---
phase: 07-knowledge-graph-and-advanced-intelligence
plan: 03
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - src/graph/entity-extractor.ts
  - src/graph/extraction-rules.ts
  - tests/graph/entity-extractor.test.ts
autonomous: true

must_haves:
  truths:
    - "Given an observation text containing a file path like 'src/auth/login.ts', a File entity is extracted with that path as its name"
    - "Given an observation containing decision language like 'decided to use JWT', a Decision entity is extracted"
    - "Given an observation mentioning a tool name like 'prettier' or 'eslint', a Tool entity is extracted"
    - "Entity extraction is conservative -- only explicit nouns matching clear patterns are extracted, ambiguous text is skipped"
    - "Extracted entities are stored as graph nodes via upsertNode from Plan 01"
  artifacts:
    - path: "src/graph/entity-extractor.ts"
      provides: "Main entity extraction pipeline: observation text -> GraphNode[]"
      exports: ["extractEntities", "EntityExtractionResult"]
    - path: "src/graph/extraction-rules.ts"
      provides: "Rule-based pattern matchers for each entity type"
      exports: ["filePathRule", "decisionRule", "toolRule", "personRule", "problemRule", "solutionRule", "projectRule"]
    - path: "tests/graph/entity-extractor.test.ts"
      provides: "Test coverage for entity extraction rules"
  key_links:
    - from: "src/graph/entity-extractor.ts"
      to: "src/graph/schema.ts"
      via: "calls upsertNode to persist extracted entities"
      pattern: "upsertNode"
    - from: "src/graph/entity-extractor.ts"
      to: "src/graph/extraction-rules.ts"
      via: "applies each rule to observation text"
      pattern: "import.*Rule.*from.*extraction-rules"
    - from: "src/graph/entity-extractor.ts"
      to: "src/graph/types.ts"
      via: "uses EntityType for typing extracted results"
      pattern: "import.*EntityType.*from.*types"
---

<objective>
Implement rule-based entity extraction that identifies typed entities from observation text and stores them as graph nodes. Start conservative -- explicit patterns only, no fuzzy matching.

Purpose: INT-09 requires automatic entity extraction for 7 entity types. This is the first intelligence layer that transforms raw observation text into structured graph data.
Output: Entity extraction pipeline with per-type rule matchers, connected to graph storage from Plan 01.
</objective>

<execution_context>
@/home/matthew/.claude/get-shit-done/workflows/execute-plan.md
@/home/matthew/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-knowledge-graph-and-advanced-intelligence/07-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create extraction rules for each entity type</name>
  <files>src/graph/extraction-rules.ts</files>
  <action>
Create src/graph/extraction-rules.ts with a rule-based pattern matcher for each of the 7 entity types.

Each rule is a function: `(text: string) => Array<{ name: string, type: EntityType, confidence: number, span: [number, number] }>`

**File rule** (`filePathRule`):
- Match patterns like `src/foo/bar.ts`, `./config.json`, `/absolute/path.ext`, `package.json`
- Regex: paths with at least one dot-extension, allowing `/`, `.`, `-`, `_` in path segments
- Confidence: 0.95 (file paths are very reliable)
- Normalize: strip leading `./`, collapse `//`

**Decision rule** (`decisionRule`):
- Match phrases following decision indicators: "decided to", "chose", "went with", "selected", "opted for", "choosing between", "decision:", "the decision was"
- Extract the clause following the indicator (up to period, comma, or end of sentence)
- Confidence: 0.7 (decision language can be ambiguous)
- Trim extracted text to max 100 chars

**Tool rule** (`toolRule`):
- Match known tool/technology names from a curated list: eslint, prettier, typescript, webpack, vite, jest, vitest, react, next, node, npm, pnpm, docker, git, prisma, drizzle, tailwind, sqlite, postgres, redis, etc. (include ~50 common dev tools)
- Case-insensitive matching, word-boundary aware
- Confidence: 0.9

**Person rule** (`personRule`):
- Match @-mentions: `@username`
- Match "by [Capitalized Name]" patterns
- Match "with [Capitalized Name]" when followed by verbs (decided with, worked with)
- Confidence: 0.6 (names are tricky, keep conservative)

**Problem rule** (`problemRule`):
- Match phrases following: "bug in", "issue with", "problem:", "error:", "failing", "broken", "doesn't work", "can't", "unable to", "crash"
- Extract the subject clause
- Confidence: 0.65

**Solution rule** (`solutionRule`):
- Match phrases following: "fixed by", "solved by", "the fix was", "solution:", "resolved by", "workaround:"
- Extract the clause
- Confidence: 0.65

**Project rule** (`projectRule`):
- Match repository-style names: "org/repo", project names in quotes after "project" keyword
- Match package.json name field references
- Confidence: 0.8

Each rule must:
- Return empty array if no matches (never throw)
- Include span (start, end character positions) for debugging
- Avoid overlapping matches (if a file path is inside a decision phrase, file wins -- higher confidence)

Export all rules as named exports AND as an array `ALL_RULES` for iteration.
  </action>
  <verify>npx tsc --noEmit src/graph/extraction-rules.ts. Test filePathRule with "Modified src/auth/login.ts to add JWT" -- should extract File entity "src/auth/login.ts". Test decisionRule with "Decided to use bcrypt instead of argon2" -- should extract Decision entity.</verify>
  <done>All 7 entity type rules exported. Each rule handles its pattern domain, returns typed results with confidence scores, and degrades gracefully (empty array on no match, no throws).</done>
</task>

<task type="auto">
  <name>Task 2: Create entity extraction pipeline and tests</name>
  <files>src/graph/entity-extractor.ts, tests/graph/entity-extractor.test.ts</files>
  <action>
**Entity extractor (src/graph/entity-extractor.ts):**

1. Define `EntityExtractionResult` interface:
   ```typescript
   interface EntityExtractionResult {
     entities: Array<{ name: string, type: EntityType, confidence: number }>;
     observationId: string;
     extractedAt: string;
   }
   ```

2. `extractEntities(text: string, observationId: string): EntityExtractionResult`:
   - Run ALL_RULES against the text
   - Collect all matches
   - Deduplicate: if same name appears from multiple rules, keep highest confidence
   - Resolve overlapping spans: higher confidence wins
   - Filter by minimum confidence threshold (default: 0.5, configurable)
   - Return sorted by confidence descending

3. `extractAndPersist(db: Database, text: string, observationId: string): Promise<GraphNode[]>`:
   - Call extractEntities
   - For each extracted entity, call upsertNode from src/graph/schema.ts
   - Append observationId to the node's observation_ids array (read-modify-write)
   - Return the persisted GraphNode objects
   - Wrap in transaction for atomicity

4. Error handling: if any single entity fails to persist, log warning and continue with remaining entities. Never fail the whole extraction because one entity had issues.

**Tests (tests/graph/entity-extractor.test.ts):**

Write tests using the project's test framework (vitest or jest -- check package.json):

1. "extracts File entity from observation with file path"
   - Input: "Modified src/components/Header.tsx to fix responsive layout"
   - Expect: File entity "src/components/Header.tsx" with confidence >= 0.9

2. "extracts Decision entity from decision language"
   - Input: "Decided to use Tailwind CSS instead of styled-components for consistency"
   - Expect: Decision entity containing "use Tailwind CSS" with confidence >= 0.6

3. "extracts Tool entity from known tool name"
   - Input: "Configured eslint with the recommended TypeScript rules"
   - Expect: Tool entity "eslint" and Tool entity "typescript"

4. "extracts multiple entity types from complex observation"
   - Input: "Fixed the authentication bug in src/auth/middleware.ts by switching from jsonwebtoken to jose library"
   - Expect: File, Problem, Solution, and Tool entities

5. "returns empty array for observation with no recognizable entities"
   - Input: "This is a general comment with nothing specific"
   - Expect: empty entities array

6. "deduplicates same entity appearing multiple times"
   - Input: "Used eslint to lint the code, then ran eslint --fix"
   - Expect: single Tool entity "eslint"

7. "respects minimum confidence threshold"
   - Input with borderline match
   - Expect: filtered out when threshold is raised
  </action>
  <verify>Run the test suite: `npx vitest run tests/graph/entity-extractor.test.ts` (or equivalent). All 7 tests pass. npx tsc --noEmit passes for both files.</verify>
  <done>Entity extraction pipeline processes observation text, identifies entities from all 7 types using rule-based matchers, deduplicates, filters by confidence, and persists as graph nodes. Test suite validates core extraction scenarios.</done>
</task>

</tasks>

<verification>
- Entity extraction from a real-world observation text (multi-sentence, mixed content) produces correct typed entities
- File paths are reliably extracted (highest confidence rule)
- Decision language captures the decision content, not just the indicator word
- No false positives on common English sentences without entities
- extractAndPersist writes nodes to SQLite and updates observation_ids
- All tests pass
</verification>

<success_criteria>
Observations are automatically analyzed for entities across all 7 types. Extraction is conservative (explicit patterns only, no fuzzy guessing). Results are persisted as graph nodes linked back to their source observations. Test coverage validates core extraction scenarios.
</success_criteria>

<output>
After completion, create `.planning/phases/07-knowledge-graph-and-advanced-intelligence/07-03-SUMMARY.md`
</output>
