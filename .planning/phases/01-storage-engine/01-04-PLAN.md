---
phase: 01-storage-engine
plan: 04
type: tdd
wave: 4
depends_on: ["01-03"]
files_modified:
  - src/storage/__tests__/concurrency.test.ts
  - src/storage/__tests__/concurrent-writer.ts
  - src/storage/__tests__/crash-recovery.test.ts
  - src/storage/__tests__/persistence.test.ts
  - src/storage/__tests__/test-utils.ts
autonomous: true

must_haves:
  truths:
    - "Three concurrent processes can read and write observations without corruption or data loss"
    - "A process crash mid-write leaves the database in a consistent state with no partial records"
    - "Observations written in one session are readable in a new session after process restart"
    - "Observations from project A are never returned when querying from project B"
    - "Schema stores original text, embedding vector (nullable), and model version metadata in every observation row"
  artifacts:
    - path: "src/storage/__tests__/concurrency.test.ts"
      provides: "Tests proving concurrent multi-process read/write safety"
      min_lines: 80
    - path: "src/storage/__tests__/crash-recovery.test.ts"
      provides: "Tests proving WAL crash recovery and transaction atomicity"
      min_lines: 40
    - path: "src/storage/__tests__/persistence.test.ts"
      provides: "Tests proving cross-session data persistence, project isolation, and schema completeness"
      min_lines: 60
    - path: "src/storage/__tests__/concurrent-writer.ts"
      provides: "Helper script forked by concurrency tests for true multi-process testing"
      min_lines: 20
    - path: "src/storage/__tests__/test-utils.ts"
      provides: "Shared test utilities: temp DB creation and cleanup"
      min_lines: 15
  key_links:
    - from: "src/storage/__tests__/concurrency.test.ts"
      to: "src/storage/__tests__/concurrent-writer.ts"
      via: "child_process.fork() spawns separate Node.js processes"
      pattern: "fork.*concurrent-writer"
    - from: "src/storage/__tests__/concurrency.test.ts"
      to: "src/storage/database.ts"
      via: "each process opens its own database connection to the same file"
      pattern: "openDatabase"
    - from: "src/storage/__tests__/crash-recovery.test.ts"
      to: "src/storage/database.ts"
      via: "opens DB, writes, simulates crash, reopens, verifies consistency"
      pattern: "openDatabase.*close"
    - from: "src/storage/__tests__/persistence.test.ts"
      to: "src/storage/search.ts"
      via: "verifies FTS5 search works after database reopen"
      pattern: "searchKeyword"
---

<objective>
Acceptance tests proving all five Phase 1 success criteria via TDD: concurrent safety, crash recovery, cross-session persistence, project isolation, and schema completeness.

Purpose: The Phase 1 success criteria are the contract this storage engine must satisfy. These tests ARE the acceptance criteria. Writing them first (RED) ensures the criteria are unambiguous, then verifying they pass (GREEN) proves the storage engine is production-ready. Concurrency tests use true multi-process testing (child_process.fork) to exercise real SQLite WAL concurrency -- not just async functions in one process.
Output: A comprehensive acceptance test suite that proves the storage engine meets all five Phase 1 success criteria from ROADMAP.md.
</objective>

<execution_context>
@/home/matthew/.claude/get-shit-done/workflows/execute-plan.md
@/home/matthew/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-storage-engine/01-RESEARCH.md
@.planning/phases/01-storage-engine/01-01-SUMMARY.md
@.planning/phases/01-storage-engine/01-02-SUMMARY.md
@.planning/phases/01-storage-engine/01-03-SUMMARY.md
</context>

<feature>
  <name>Storage Engine Acceptance Tests</name>
  <files>
    src/storage/__tests__/test-utils.ts
    src/storage/__tests__/concurrent-writer.ts
    src/storage/__tests__/concurrency.test.ts
    src/storage/__tests__/crash-recovery.test.ts
    src/storage/__tests__/persistence.test.ts
  </files>
  <behavior>
    **Success Criterion 1 -- Persistence (MEM-01):**
    - Open database, write observations with full metadata, close database
    - Reopen database as a new "session"
    - All observations are readable with correct content, timestamps, source, and metadata
    - FTS5 search works after reopen (index persisted with data)

    **Success Criterion 2 -- Concurrency (MEM-07):**
    - 3 separate Node.js processes write 100 observations each to the SAME database file simultaneously
    - After all complete, database contains exactly 300 observations with zero lost writes
    - No SQLITE_BUSY errors propagate to callers (busy_timeout = 5000ms absorbs contention)
    - A reader process running concurrently with writers always sees consistent (not corrupted) data

    **Success Criterion 3 -- Crash Recovery (MEM-08):**
    - Open database, insert some committed observations
    - Start a multi-row transaction, insert rows, simulate crash (do NOT commit or close)
    - Reopen database
    - Committed observations are present (durability)
    - Uncommitted transaction rows are absent (atomicity -- WAL rollback)

    **Success Criterion 4 -- Project Isolation (MEM-06, SRC-05):**
    - Write observations to project A (hash "aaaa1111")
    - Query via ObservationRepository from project B (hash "bbbb2222") -- zero results
    - Search via SearchEngine from project B -- zero results
    - Write to project B, query project A -- only project A's observations returned

    **Success Criterion 5 -- Schema Completeness (MEM-09):**
    - Insert observation WITH all fields: content, source, embedding (Float32Array), embeddingModel, embeddingVersion
    - Read back -- all fields match exactly (including Float32Array values)
    - Insert observation WITHOUT embedding fields (all nullable)
    - Read back -- embedding fields are null, other fields correct
  </behavior>
  <implementation>
    **Test Utilities (create first):**

    `src/storage/__tests__/test-utils.ts`:
    - `createTempDb(): { config: DatabaseConfig; cleanup: () => void }` -- creates a temp directory via `mkdtempSync`, returns a DatabaseConfig pointing there, and a cleanup function that removes the directory and all files.
    - Each test uses its own temp directory to avoid cross-test interference.
    - Import `mkdtempSync`, `rmSync` from `node:fs`, `tmpdir` from `node:os`, `join` from `node:path`.

    **Concurrent Writer Helper:**

    `src/storage/__tests__/concurrent-writer.ts`:
    - Standalone script that receives `dbPath` and `projectHash` and `count` via process.argv
    - Opens its own database connection via openDatabase
    - Creates an ObservationRepository
    - Writes `count` observations in a loop (each with unique content like "obs-{processId}-{i}")
    - Closes database and exits with code 0
    - On any error: log to stderr and exit with code 1
    - This file is NOT a test -- it is forked by the concurrency test as a separate process

    **Concurrency Tests:**

    `src/storage/__tests__/concurrency.test.ts`:
    - Use `child_process.fork()` to spawn 3 instances of concurrent-writer.ts
    - Each writes 100 observations to the same database file
    - Wait for all 3 to exit (Promise.all on exit events)
    - Assert all exit with code 0 (no SQLITE_BUSY errors)
    - Open the database and count observations: expect exactly 300
    - Verify no duplicate IDs
    - Set test timeout to 30s (`{ timeout: 30000 }`) -- concurrent writes with busy_timeout retries may take time

    Also test concurrent read during write:
    - Fork a writer process that writes 200 observations slowly (with small delays)
    - In the parent process, repeatedly read observations during the writes
    - Assert no corrupted data (all returned observations have valid content, no partial reads)

    **Crash Recovery Tests:**

    `src/storage/__tests__/crash-recovery.test.ts`:
    - Open database at temp path
    - Insert 5 "committed" observations normally (through repository)
    - Get the raw db handle and manually execute uncommitted transaction:
      ```typescript
      db.exec('BEGIN');
      db.exec("INSERT INTO observations (project_hash, content) VALUES ('test', 'uncommitted-1')");
      db.exec("INSERT INTO observations (project_hash, content) VALUES ('test', 'uncommitted-2')");
      // Do NOT commit -- simulate crash by destroying connection
      ```
    - Actually, for better crash simulation, fork a child process that:
      - Opens database
      - Inserts committed observations
      - Starts a transaction with manual BEGIN
      - Inserts uncommitted observations
      - Calls `process.exit(1)` without committing (simulates hard crash)
    - In parent: wait for child to exit
    - Open database again
    - Count observations: should be exactly 5 (committed only)
    - Verify none of the "uncommitted" content exists
    - Verify WAL mode is still active after recovery

    **Persistence Tests:**

    `src/storage/__tests__/persistence.test.ts`:
    - **Cross-session persistence:** Open DB, create 5 observations (varied content), close. Reopen. Verify all 5 readable with correct content and timestamps. Verify FTS5 search finds them after reopen.
    - **Project isolation across sessions:** In session 1, write to projects A and B. Close. In session 2, verify project A only sees A's observations, project B only sees B's.
    - **Embedding roundtrip:** Create observation with Float32Array embedding [0.1, 0.2, 0.3, ...384 values]. Read back. Verify Float32Array values match within floating point tolerance.
    - **Schema completeness:** Create observation with ALL fields populated. Read back. Verify every field matches. Create observation with only required fields (embedding null). Read back. Verify nulls are correct.

    **TDD Cycle:**
    - RED: Write all tests. They should pass because Plans 01-01 through 01-03 implemented the storage engine. If any fail, that indicates a bug in the implementation that this plan must fix.
    - GREEN: If all tests pass immediately, great -- the implementation is correct. If any fail, fix the storage implementation (database.ts, observations.ts, etc.) to make them pass.
    - REFACTOR: Clean up any test helpers, ensure all temp databases are cleaned up, ensure tests are deterministic and parallelizable.
  </implementation>
</feature>

<verification>
- `npx vitest run` passes ALL tests with zero failures
- Concurrency test proves 3 processes write 300 observations without data loss
- Crash recovery test proves uncommitted transactions roll back cleanly
- Persistence test proves data survives close/reopen cycle including FTS5 index
- Project isolation test proves zero cross-project leakage in CRUD and search
- Schema test proves embedding Float32Array roundtrips correctly with model metadata
- No flaky tests (run twice to confirm determinism)
</verification>

<success_criteria>
All five Phase 1 success criteria from ROADMAP.md are proven by passing tests:
1. Observations written in one session are readable in a new session after process restart (persistence.test.ts)
2. Three concurrent processes can read and write observations without corruption or data loss (concurrency.test.ts)
3. A process crash mid-write leaves the database in a consistent state with no partial records (crash-recovery.test.ts)
4. Observations from project A are never returned when querying from project B (persistence.test.ts)
5. Schema stores original text, embedding vector (nullable), and model version metadata in every observation row (persistence.test.ts)
</success_criteria>

<output>
After completion, create `.planning/phases/01-storage-engine/01-04-SUMMARY.md`
</output>
