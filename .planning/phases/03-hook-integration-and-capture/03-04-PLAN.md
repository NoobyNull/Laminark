---
phase: 03-hook-integration-and-capture
plan: 04
type: execute
wave: 3
depends_on: ["03-01", "03-02", "03-03"]
files_modified:
  - hooks/hooks.json
  - src/ingest/pipeline.ts
  - src/ingest/__tests__/pipeline.test.ts
  - src/ingest/__tests__/e2e-capture.test.ts
autonomous: true

must_haves:
  truths:
    - "hooks.json correctly maps PostToolUse, SessionStart, SessionEnd, and Stop events to their respective scripts"
    - "PostToolUse and Stop hooks are async (non-blocking), SessionStart is sync"
    - "End-to-end: a simulated PostToolUse event flows from hook script through privacy filter, admission filter, and arrives as a stored observation"
    - "End-to-end: a simulated noise event (npm install output) is rejected and never stored"
    - "End-to-end: a simulated sensitive event (.env read) is excluded and never stored"
    - "Session lifecycle: session start creates a session record, session end marks it as ended"
  artifacts:
    - path: "hooks/hooks.json"
      provides: "Claude Code hook event configuration"
      contains: "PostToolUse"
    - path: "src/ingest/pipeline.ts"
      provides: "Complete ingest pipeline wiring: receiver -> privacy -> normalizer -> admission -> storage"
      exports: ["IngestPipeline", "createIngestPipeline"]
  key_links:
    - from: "hooks/hooks.json"
      to: "scripts/hook-dispatcher.sh"
      via: "maps hook events to shell scripts"
      pattern: "hook-dispatcher\\.sh"
    - from: "hooks/hooks.json"
      to: "scripts/session-start.sh"
      via: "maps SessionStart to sync script"
      pattern: "session-start\\.sh"
    - from: "src/ingest/pipeline.ts"
      to: "src/ingest/receiver.ts"
      via: "creates receiver with pipeline callbacks"
      pattern: "import.*createIngestReceiver"
    - from: "src/ingest/pipeline.ts"
      to: "src/ingest/admission-filter.ts"
      via: "uses AdmissionFilter to gate observations"
      pattern: "import.*AdmissionFilter"
    - from: "src/ingest/pipeline.ts"
      to: "src/ingest/privacy-filter.ts"
      via: "uses PrivacyFilter for redaction"
      pattern: "import.*PrivacyFilter"
---

<objective>
Wire the complete ingest pipeline together and create the hooks.json configuration file. This plan connects all Phase 3 components into a working end-to-end capture system: Claude Code fires a hook event, the hook script dispatches it, the ingest pipeline processes it through privacy filter, normalizer, and admission filter, and stores qualifying observations.

Purpose: This is the integration and verification plan. Plans 03-01 through 03-03 created individual components. This plan wires them together into a complete pipeline and proves the full capture flow works end-to-end. This directly validates all four Phase 3 success criteria.

Output: hooks.json configuration file, IngestPipeline module that orchestrates all components, and end-to-end integration tests.
</objective>

<execution_context>
@/home/matthew/.claude/get-shit-done/workflows/execute-plan.md
@/home/matthew/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/research/ARCHITECTURE.md

Plan 03-01 provides: hook-dispatcher.sh, session-start.sh, session-end.sh, ingest receiver (HTTP), normalizer
Plan 03-02 provides: AdmissionFilter, NoiseDetector
Plan 03-03 provides: PrivacyFilter, privacy config integration into normalizer

Claude Code hooks.json format (from research):
{
  "hooks": {
    "PostToolUse": [{ "matcher": {}, "command": "bash scripts/hook-dispatcher.sh", "async": true }],
    "SessionStart": [{ "matcher": {}, "command": "bash scripts/session-start.sh" }],
    ...
  }
}
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create hooks.json and IngestPipeline orchestrator</name>
  <files>hooks/hooks.json, src/ingest/pipeline.ts</files>
  <action>
Create hooks/hooks.json:
```json
{
  "hooks": {
    "PostToolUse": [
      {
        "matcher": {},
        "command": "bash ./scripts/hook-dispatcher.sh",
        "async": true
      }
    ],
    "PostToolUseFailure": [
      {
        "matcher": {},
        "command": "bash ./scripts/hook-dispatcher.sh",
        "async": true
      }
    ],
    "SessionStart": [
      {
        "matcher": {},
        "command": "bash ./scripts/session-start.sh"
      }
    ],
    "SessionEnd": [
      {
        "matcher": {},
        "command": "bash ./scripts/session-end.sh",
        "async": true
      }
    ],
    "Stop": [
      {
        "matcher": {},
        "command": "bash ./scripts/hook-dispatcher.sh",
        "async": true
      }
    ]
  }
}
```

Notes on hooks.json:
- PostToolUse: async: true (non-blocking, most common event, fires for every tool call)
- PostToolUseFailure: async: true (capture failed tool calls -- high signal for debugging context)
- SessionStart: NO async field means sync/blocking (needed for future context injection in Phase 5, but Phase 3 just tracks session start)
- SessionEnd: async: true (fire-and-forget session close)
- Stop: async: true (fire-and-forget, capture final activity)
- matcher: {} means match all events (no filtering by tool name)
- Commands use relative paths from the plugin root

Create src/ingest/pipeline.ts:

Export type PipelineStats = { received: number, admitted: number, rejected_noise: number, rejected_privacy: number, rejected_relevance: number }

Export class IngestPipeline:
- Constructor takes: { storage: ObservationStorage (from Phase 1), sessionStorage: SessionStorage (from Phase 1), port?: number (default 37819) }
- Creates: PrivacyFilter (with project config), AdmissionFilter (with default config), IngestReceiver
- Wires the callbacks:
  - onObservation: (1) parse payload, (2) privacy filter redact, (3) normalize, (4) admission filter, (5) if admitted: write to storage via storage.createObservation(), (6) update stats
  - onSessionStart: (1) create session record via sessionStorage.createSession({ id: payload.session_id, project_dir: payload.project_dir, started_at: now }), (2) update stats
  - onSessionEnd: (1) update session record via sessionStorage.endSession(payload.session_id, now), (2) update stats
- Method start(): Promise<void> -- starts the HTTP receiver
- Method stop(): Promise<void> -- stops the HTTP receiver
- Method getStats(): PipelineStats -- returns current stats
- Method resetStats(): void

Export createIngestPipeline(opts): IngestPipeline as convenience factory.

The pipeline MUST handle errors at each stage gracefully:
- If privacy filter throws, log error and skip the observation (do not crash)
- If normalizer returns null, count as rejected and continue
- If admission filter rejects, count as rejected and continue
- If storage write fails, log error and continue (do not crash the pipeline)
  </action>
  <verify>
Run: node -e "const h = require('./hooks/hooks.json'); console.log(Object.keys(h.hooks))" (verify hooks.json is valid JSON with expected keys)
Run: npx vitest run src/ingest/__tests__/pipeline.test.ts --reporter=verbose (after creating tests in Task 2)
  </verify>
  <done>
hooks.json maps all 5 hook events to their shell scripts with correct async/sync settings. IngestPipeline orchestrates the full capture flow: receive -> privacy -> normalize -> admit -> store. Stats track received, admitted, and rejected counts by category.
  </done>
</task>

<task type="auto">
  <name>Task 2: End-to-end integration tests for the complete capture pipeline</name>
  <files>src/ingest/__tests__/pipeline.test.ts, src/ingest/__tests__/e2e-capture.test.ts</files>
  <action>
Create src/ingest/__tests__/pipeline.test.ts -- unit tests for IngestPipeline:
- Test pipeline wiring: mock storage and verify that a valid observation payload flows through all stages and calls storage.createObservation()
- Test noise rejection: POST a payload with "added 150 packages in 4.5s" content, verify storage.createObservation is NOT called, stats show rejected_noise=1
- Test privacy exclusion: POST a payload touching ".env.local" file, verify storage.createObservation is NOT called, stats show rejected_privacy=1
- Test session lifecycle: POST to /session/start, verify sessionStorage.createSession called. POST to /session/end, verify sessionStorage.endSession called
- Test error resilience: mock storage.createObservation to throw, verify pipeline does not crash and continues processing next observation
- Test stats accuracy: send 5 observations (2 valid, 1 noise, 1 privacy, 1 low relevance), verify stats match

Create src/ingest/__tests__/e2e-capture.test.ts -- full end-to-end integration test:
- Start IngestPipeline with a real (in-memory) SQLite database (using Phase 1 storage)
- If Phase 1 storage is not available, create a minimal mock that implements the storage interface
- Simulate the full hook flow:
  1. Send HTTP POST to localhost:37819/session/start with { session_id: "test-session-1", project_dir: "/tmp/test-project" }
  2. Send HTTP POST to localhost:37819/ingest with a PostToolUse payload: { session_id: "test-session-1", event: { tool_name: "Write", tool_input: "src/auth.ts", tool_output: "Created file src/auth.ts with JWT authentication logic" }, hook_type: "PostToolUse" }
  3. Verify the observation was stored with content containing "Write" and "auth.ts" and "JWT"
  4. Send HTTP POST to localhost:37819/ingest with a noise payload: { ..., event: { tool_name: "Bash", tool_output: "added 150 packages in 4.5s\n50 packages are looking for funding" }, hook_type: "PostToolUse" }
  5. Verify this observation was NOT stored (noise rejection)
  6. Send HTTP POST to localhost:37819/ingest with a sensitive payload: { ..., event: { tool_name: "Read", tool_input: ".env.local", tool_output: "STRIPE_KEY=sk_live_abc123xyz\nDATABASE_URL=postgresql://user:pass@host/db" }, hook_type: "PostToolUse" }
  7. Verify this observation was either excluded (file pattern) or redacted (no raw key values in stored content)
  8. Send HTTP POST to localhost:37819/session/end with { session_id: "test-session-1" }
  9. Verify session record exists with start and end timestamps
  10. Verify pipeline stats: received=3, admitted=1, rejected_noise=1, rejected_privacy=1

Use actual HTTP requests (node:http or fetch) in the e2e test, not mocked calls. This proves the full network path works.
  </action>
  <verify>
Run: npx vitest run src/ingest/__tests__/pipeline.test.ts src/ingest/__tests__/e2e-capture.test.ts --reporter=verbose
All tests pass. The e2e test proves the complete flow: hook payload -> HTTP -> privacy filter -> normalizer -> admission filter -> storage.
  </verify>
  <done>
Integration tests prove: (1) valid observations flow through the pipeline and are stored, (2) noise is rejected before storage, (3) sensitive content is excluded/redacted, (4) session lifecycle is tracked. Pipeline stats accurately reflect admission/rejection counts. The full HTTP path works end-to-end.
  </done>
</task>

</tasks>

<verification>
Full phase verification (run after all 4 plans complete):

1. hooks.json exists and maps PostToolUse, PostToolUseFailure, SessionStart, SessionEnd, Stop to correct scripts
2. PostToolUse and Stop are async: true, SessionStart is sync (no async field)
3. npx vitest run src/ingest/ -- all tests pass (unit + integration + e2e)
4. Pipeline stats show correct admit/reject counts for mixed observation types
5. No sensitive content (API keys, .env values) appears in stored observations
6. Session records have both start and end timestamps after lifecycle flow
7. The shell scripts exist, are executable, and exit 0 even when the core process is not running

Phase 3 Success Criteria Verification:
- SC1 (MEM-02): e2e test proves PostToolUse payload flows to storage automatically
- SC2 (MEM-03): e2e test proves session start/end creates session records with unique IDs
- SC3 (MEM-10): e2e test proves npm install output is rejected by admission filter
- SC4 (DQ-02): e2e test proves .env content is excluded/redacted by privacy filter
</verification>

<success_criteria>
- hooks.json correctly configures all 5 Claude Code hook events
- IngestPipeline orchestrates the complete capture flow with error resilience
- End-to-end tests prove all 4 Phase 3 success criteria are met
- Pipeline handles errors at each stage without crashing
- Stats accurately track admission and rejection counts
</success_criteria>

<output>
After completion, create `.planning/phases/03-hook-integration-and-capture/03-04-SUMMARY.md`
</output>
