{"version":3,"file":"sessions-bHB4xCD4.mjs","names":[],"sources":["../src/shared/debug.ts","../src/storage/migrations.ts","../src/storage/database.ts","../src/shared/types.ts","../src/storage/observations.ts","../src/storage/sessions.ts"],"sourcesContent":["import { isDebugEnabled } from './config.js';\n\n/**\n * Internal cached state for debug mode.\n * Resolved on first call and never changes (debug mode is process-lifetime).\n */\nlet _enabled: boolean | null = null;\n\nfunction enabled(): boolean {\n  if (_enabled === null) {\n    _enabled = isDebugEnabled();\n  }\n  return _enabled;\n}\n\n/**\n * Logs a debug message to stderr when debug mode is active.\n *\n * When debug is disabled (the default), this is a near-zero-cost no-op after the\n * first call -- the cached flag short-circuits immediately.\n *\n * Format: `[ISO_TIMESTAMP] [LAMINARK:category] message {json_data}`\n *\n * @param category - Debug category (e.g., 'db', 'obs', 'search', 'session')\n * @param message - Human-readable log message\n * @param data - Optional structured data to include (keep lightweight -- no large payloads)\n */\nexport function debug(\n  category: string,\n  message: string,\n  data?: Record<string, unknown>,\n): void {\n  if (!enabled()) {\n    return;\n  }\n\n  const timestamp = new Date().toISOString();\n  let line = `[${timestamp}] [LAMINARK:${category}] ${message}`;\n  if (data !== undefined) {\n    line += ` ${JSON.stringify(data)}`;\n  }\n  process.stderr.write(line + '\\n');\n}\n\n/**\n * Wraps a synchronous function with timing instrumentation.\n *\n * When debug is disabled, calls `fn()` directly with zero overhead --\n * no timing measurement, no wrapping.\n *\n * @param category - Debug category for the log line\n * @param message - Description of the operation being timed\n * @param fn - Synchronous function to execute and time\n * @returns The return value of `fn()`\n */\nexport function debugTimed<T>(\n  category: string,\n  message: string,\n  fn: () => T,\n): T {\n  if (!enabled()) {\n    return fn();\n  }\n\n  const start = performance.now();\n  const result = fn();\n  const duration = (performance.now() - start).toFixed(2);\n  debug(category, `${message} (${duration}ms)`);\n  return result;\n}\n","import type BetterSqlite3 from 'better-sqlite3';\n\n/**\n * A versioned schema migration.\n * Migrations are applied in order and tracked in the _migrations table.\n */\nexport interface Migration {\n  version: number;\n  name: string;\n  up: string; // SQL to execute\n}\n\n/**\n * All schema migrations in order.\n *\n * Migration 001: Observations table with INTEGER PRIMARY KEY AUTOINCREMENT\n *   (critical for FTS5 content_rowid stability across VACUUM).\n * Migration 002: Sessions table for session lifecycle tracking.\n * Migration 003: FTS5 external content table with porter+unicode61 tokenizer\n *   and three sync triggers (INSERT, UPDATE, DELETE).\n * Migration 004: sqlite-vec vec0 table for 384-dim embeddings (conditional).\n * Migration 005: Add title column to observations and rebuild FTS5 with\n *   title+content dual-column indexing.\n * Migration 006: Recreate vec0 table with cosine distance metric (conditional).\n * Migration 007: Context stashes table for topic detection thread snapshots.\n * Migration 008: Threshold history table for EWMA adaptive threshold seeding.\n * Migration 009: Shift decisions table for topic shift decision logging.\n */\nexport const MIGRATIONS: Migration[] = [\n  {\n    version: 1,\n    name: 'create_observations',\n    up: `\n      CREATE TABLE observations (\n        rowid INTEGER PRIMARY KEY AUTOINCREMENT,\n        id TEXT NOT NULL UNIQUE DEFAULT (lower(hex(randomblob(16)))),\n        project_hash TEXT NOT NULL,\n        content TEXT NOT NULL,\n        source TEXT NOT NULL DEFAULT 'unknown',\n        session_id TEXT,\n        embedding BLOB,\n        embedding_model TEXT,\n        embedding_version TEXT,\n        created_at TEXT NOT NULL DEFAULT (datetime('now')),\n        updated_at TEXT NOT NULL DEFAULT (datetime('now')),\n        deleted_at TEXT\n      );\n\n      CREATE INDEX idx_observations_project ON observations(project_hash);\n      CREATE INDEX idx_observations_session ON observations(session_id);\n      CREATE INDEX idx_observations_created ON observations(created_at);\n      CREATE INDEX idx_observations_deleted ON observations(deleted_at) WHERE deleted_at IS NOT NULL;\n    `,\n  },\n  {\n    version: 2,\n    name: 'create_sessions',\n    up: `\n      CREATE TABLE sessions (\n        id TEXT PRIMARY KEY,\n        project_hash TEXT NOT NULL,\n        started_at TEXT NOT NULL DEFAULT (datetime('now')),\n        ended_at TEXT,\n        summary TEXT\n      );\n\n      CREATE INDEX idx_sessions_project ON sessions(project_hash);\n      CREATE INDEX idx_sessions_started ON sessions(started_at);\n    `,\n  },\n  {\n    version: 3,\n    name: 'create_fts5_observations',\n    up: `\n      CREATE VIRTUAL TABLE observations_fts USING fts5(\n        content,\n        content='observations',\n        content_rowid='rowid',\n        tokenize='porter unicode61'\n      );\n\n      -- Sync trigger: INSERT\n      CREATE TRIGGER observations_ai AFTER INSERT ON observations BEGIN\n        INSERT INTO observations_fts(rowid, content)\n          VALUES (new.rowid, new.content);\n      END;\n\n      -- Sync trigger: UPDATE (delete old entry, insert new)\n      CREATE TRIGGER observations_au AFTER UPDATE ON observations BEGIN\n        INSERT INTO observations_fts(observations_fts, rowid, content)\n          VALUES('delete', old.rowid, old.content);\n        INSERT INTO observations_fts(rowid, content)\n          VALUES (new.rowid, new.content);\n      END;\n\n      -- Sync trigger: DELETE\n      CREATE TRIGGER observations_ad AFTER DELETE ON observations BEGIN\n        INSERT INTO observations_fts(observations_fts, rowid, content)\n          VALUES('delete', old.rowid, old.content);\n      END;\n    `,\n  },\n  {\n    version: 4,\n    name: 'create_vec0_embeddings',\n    up: `\n      CREATE VIRTUAL TABLE IF NOT EXISTS observation_embeddings USING vec0(\n        observation_id TEXT PRIMARY KEY,\n        embedding float[384]\n      );\n    `,\n  },\n  {\n    version: 5,\n    name: 'add_observation_title',\n    up: `\n      ALTER TABLE observations ADD COLUMN title TEXT;\n\n      DROP TRIGGER observations_ai;\n      DROP TRIGGER observations_au;\n      DROP TRIGGER observations_ad;\n      DROP TABLE observations_fts;\n\n      CREATE VIRTUAL TABLE observations_fts USING fts5(\n        title,\n        content,\n        content='observations',\n        content_rowid='rowid',\n        tokenize='porter unicode61'\n      );\n\n      CREATE TRIGGER observations_ai AFTER INSERT ON observations BEGIN\n        INSERT INTO observations_fts(rowid, title, content)\n          VALUES (new.rowid, new.title, new.content);\n      END;\n\n      CREATE TRIGGER observations_au AFTER UPDATE ON observations BEGIN\n        INSERT INTO observations_fts(observations_fts, rowid, title, content)\n          VALUES('delete', old.rowid, old.title, old.content);\n        INSERT INTO observations_fts(rowid, title, content)\n          VALUES (new.rowid, new.title, new.content);\n      END;\n\n      CREATE TRIGGER observations_ad AFTER DELETE ON observations BEGIN\n        INSERT INTO observations_fts(observations_fts, rowid, title, content)\n          VALUES('delete', old.rowid, old.title, old.content);\n      END;\n\n      INSERT INTO observations_fts(observations_fts) VALUES('rebuild');\n    `,\n  },\n  {\n    version: 6,\n    name: 'recreate_vec0_cosine_distance',\n    up: `\n      DROP TABLE IF EXISTS observation_embeddings;\n      CREATE VIRTUAL TABLE IF NOT EXISTS observation_embeddings USING vec0(\n        observation_id TEXT PRIMARY KEY,\n        embedding float[384] distance_metric=cosine\n      );\n    `,\n  },\n  {\n    version: 7,\n    name: 'create_context_stashes',\n    up: `\n      CREATE TABLE context_stashes (\n        id TEXT PRIMARY KEY,\n        project_id TEXT NOT NULL,\n        session_id TEXT NOT NULL,\n        topic_label TEXT NOT NULL,\n        summary TEXT NOT NULL,\n        observation_snapshots TEXT NOT NULL,\n        observation_ids TEXT NOT NULL,\n        status TEXT NOT NULL DEFAULT 'stashed',\n        created_at TEXT NOT NULL DEFAULT (datetime('now')),\n        resumed_at TEXT\n      );\n\n      CREATE INDEX idx_stashes_project_status_created\n        ON context_stashes(project_id, status, created_at DESC);\n\n      CREATE INDEX idx_stashes_session\n        ON context_stashes(session_id);\n    `,\n  },\n  {\n    version: 8,\n    name: 'create_threshold_history',\n    up: `\n      CREATE TABLE threshold_history (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        project_id TEXT NOT NULL,\n        session_id TEXT NOT NULL,\n        final_ewma_distance REAL NOT NULL,\n        final_ewma_variance REAL NOT NULL,\n        observation_count INTEGER NOT NULL,\n        created_at TEXT NOT NULL DEFAULT (datetime('now'))\n      );\n\n      CREATE INDEX idx_threshold_history_project\n        ON threshold_history(project_id, created_at DESC);\n    `,\n  },\n  {\n    version: 9,\n    name: 'create_shift_decisions',\n    up: `\n      CREATE TABLE shift_decisions (\n        id TEXT PRIMARY KEY,\n        project_id TEXT NOT NULL,\n        session_id TEXT NOT NULL,\n        observation_id TEXT,\n        distance REAL NOT NULL,\n        threshold REAL NOT NULL,\n        ewma_distance REAL,\n        ewma_variance REAL,\n        sensitivity_multiplier REAL,\n        shifted INTEGER NOT NULL,\n        confidence REAL,\n        stash_id TEXT,\n        created_at TEXT NOT NULL DEFAULT (datetime('now'))\n      );\n\n      CREATE INDEX idx_shift_decisions_session\n        ON shift_decisions(project_id, session_id, created_at DESC);\n\n      CREATE INDEX idx_shift_decisions_shifted\n        ON shift_decisions(shifted, created_at DESC);\n    `,\n  },\n];\n\n/**\n * Applies unapplied schema migrations in order.\n *\n * Creates a _migrations tracking table if it does not exist, then applies\n * each migration whose version exceeds the current max applied version.\n * Each migration runs inside a transaction for atomicity.\n *\n * Migrations 004 and 006 (vec0 tables) are only applied when hasVectorSupport\n * is true. If sqlite-vec is not available, they are silently skipped and will\n * be applied on a future run when the extension becomes available.\n *\n * @param db - An open better-sqlite3 database connection\n * @param hasVectorSupport - Whether sqlite-vec loaded successfully\n */\nexport function runMigrations(\n  db: BetterSqlite3.Database,\n  hasVectorSupport: boolean,\n): void {\n  // Create tracking table\n  db.exec(`\n    CREATE TABLE IF NOT EXISTS _migrations (\n      version INTEGER PRIMARY KEY,\n      name TEXT NOT NULL,\n      applied_at TEXT NOT NULL DEFAULT (datetime('now'))\n    )\n  `);\n\n  // Get current max applied version\n  const maxVersion = db.prepare(\n    'SELECT COALESCE(MAX(version), 0) FROM _migrations',\n  ).pluck().get() as number;\n\n  // Prepare insert statement\n  const insertMigration = db.prepare(\n    'INSERT INTO _migrations (version, name) VALUES (?, ?)',\n  );\n\n  // Apply each unapplied migration in a transaction\n  const applyMigration = db.transaction((m: Migration) => {\n    db.exec(m.up);\n    insertMigration.run(m.version, m.name);\n  });\n\n  for (const migration of MIGRATIONS) {\n    if (migration.version <= maxVersion) {\n      continue;\n    }\n\n    // Skip vec0 migrations if sqlite-vec is not available\n    if ((migration.version === 4 || migration.version === 6) && !hasVectorSupport) {\n      continue;\n    }\n\n    applyMigration(migration);\n  }\n}\n","import Database from 'better-sqlite3';\nimport * as sqliteVec from 'sqlite-vec';\nimport { mkdirSync } from 'node:fs';\nimport { dirname } from 'node:path';\n\nimport { debug } from '../shared/debug.js';\nimport type { DatabaseConfig } from '../shared/types.js';\nimport { runMigrations } from './migrations.js';\n\n/**\n * Wrapper around a configured better-sqlite3 database instance.\n * Provides lifecycle methods (close, checkpoint) and tracks whether\n * the sqlite-vec extension loaded successfully.\n */\nexport interface LaminarkDatabase {\n  db: Database.Database;\n  hasVectorSupport: boolean;\n  close(): void;\n  checkpoint(): void;\n}\n\n/**\n * Opens a SQLite database with WAL mode, correct PRAGMA order,\n * optional sqlite-vec extension loading, and schema migrations.\n *\n * Single connection per process by design -- better-sqlite3 is synchronous,\n * so connection pooling adds zero benefit.\n *\n * @param config - Database path and busy timeout configuration\n * @returns A configured LaminarkDatabase instance\n */\nexport function openDatabase(config: DatabaseConfig): LaminarkDatabase {\n  // 1. Ensure directory exists\n  mkdirSync(dirname(config.dbPath), { recursive: true });\n\n  // 2. Create connection\n  const db = new Database(config.dbPath);\n\n  // 3. Set PRAGMAs in correct order (order matters per research)\n  //    WAL mode MUST be first -- synchronous = NORMAL is only safe with WAL\n  const journalMode = db.pragma('journal_mode = WAL', {\n    simple: true,\n  }) as string;\n  if (journalMode !== 'wal') {\n    console.warn(\n      `WARNING: WAL mode not active (got '${journalMode}'). ` +\n        'Database may be on a read-only filesystem or otherwise restricted.',\n    );\n  }\n\n  // busy_timeout -- per-connection, must set every time\n  db.pragma(`busy_timeout = ${config.busyTimeout}`);\n\n  // synchronous NORMAL -- safe ONLY with WAL, faster than FULL\n  db.pragma('synchronous = NORMAL');\n\n  // cache_size -- negative = KiB (64MB)\n  db.pragma('cache_size = -64000');\n\n  // foreign_keys -- per-connection, not persistent\n  db.pragma('foreign_keys = ON');\n\n  // temp_store -- temp tables in memory\n  db.pragma('temp_store = MEMORY');\n\n  // wal_autocheckpoint -- explicit default, prevents WAL growth\n  db.pragma('wal_autocheckpoint = 1000');\n\n  debug('db', 'PRAGMAs configured', { journalMode, busyTimeout: config.busyTimeout });\n\n  // 4. Load sqlite-vec with graceful degradation\n  let hasVectorSupport = false;\n  try {\n    sqliteVec.load(db);\n    hasVectorSupport = true;\n  } catch {\n    // Vector search unavailable -- keyword-only mode\n  }\n\n  debug('db', hasVectorSupport ? 'sqlite-vec loaded' : 'sqlite-vec unavailable, keyword-only mode');\n\n  // 5. Run migrations\n  runMigrations(db, hasVectorSupport);\n\n  debug('db', 'Database opened', { path: config.dbPath, hasVectorSupport });\n\n  // 6. Return LaminarkDatabase\n  return {\n    db,\n    hasVectorSupport,\n\n    close(): void {\n      try {\n        // Flush WAL before shutdown\n        db.pragma('wal_checkpoint(PASSIVE)');\n      } catch {\n        // If checkpoint fails (e.g., locked), still close\n      }\n      debug('db', 'Database closed');\n      db.close();\n    },\n\n    checkpoint(): void {\n      db.pragma('wal_checkpoint(PASSIVE)');\n    },\n  };\n}\n","import { z } from 'zod';\n\n// =============================================================================\n// Database Layer Types (snake_case, matches SQL columns)\n// =============================================================================\n\n/**\n * ObservationRow -- the raw database row shape.\n * Uses snake_case to match SQL column names directly.\n * rowid is INTEGER PRIMARY KEY AUTOINCREMENT for FTS5 content_rowid compatibility.\n */\nexport const ObservationRowSchema = z.object({\n  rowid: z.number(),\n  id: z.string(),\n  project_hash: z.string(),\n  content: z.string(),\n  title: z.string().nullable(),\n  source: z.string(),\n  session_id: z.string().nullable(),\n  embedding: z.instanceof(Buffer).nullable(),\n  embedding_model: z.string().nullable(),\n  embedding_version: z.string().nullable(),\n  created_at: z.string(),\n  updated_at: z.string(),\n  deleted_at: z.string().nullable(),\n});\n\nexport type ObservationRow = z.infer<typeof ObservationRowSchema>;\n\n// =============================================================================\n// Application Layer Types (camelCase)\n// =============================================================================\n\n/**\n * Observation -- the application-layer shape.\n * Uses camelCase for idiomatic TypeScript.\n * embedding is Float32Array (converted from Buffer during mapping).\n */\nexport interface Observation {\n  rowid: number;\n  id: string;\n  projectHash: string;\n  content: string;\n  title: string | null;\n  source: string;\n  sessionId: string | null;\n  embedding: Float32Array | null;\n  embeddingModel: string | null;\n  embeddingVersion: string | null;\n  createdAt: string;\n  updatedAt: string;\n  deletedAt: string | null;\n}\n\n// =============================================================================\n// Input Types (validated with Zod)\n// =============================================================================\n\n/**\n * ObservationInsert -- input for creating observations.\n * Validated at runtime via Zod schema.\n */\nexport const ObservationInsertSchema = z.object({\n  content: z.string().min(1).max(100_000),\n  title: z.string().max(200).nullable().default(null),\n  source: z.string().default('unknown'),\n  sessionId: z.string().nullable().default(null),\n  embedding: z.instanceof(Float32Array).nullable().default(null),\n  embeddingModel: z.string().nullable().default(null),\n  embeddingVersion: z.string().nullable().default(null),\n});\n\nexport type ObservationInsert = z.input<typeof ObservationInsertSchema>;\n\n// =============================================================================\n// Session Types\n// =============================================================================\n\nexport interface Session {\n  id: string;\n  projectHash: string;\n  startedAt: string;\n  endedAt: string | null;\n  summary: string | null;\n}\n\n// =============================================================================\n// Search Types\n// =============================================================================\n\nexport interface SearchResult {\n  observation: Observation;\n  score: number;\n  matchType: 'fts' | 'vector' | 'hybrid';\n  snippet: string;\n}\n\n// =============================================================================\n// Configuration Types\n// =============================================================================\n\nexport interface DatabaseConfig {\n  dbPath: string;\n  busyTimeout: number;\n}\n\n// =============================================================================\n// Mapping Helpers\n// =============================================================================\n\n/**\n * Maps a snake_case ObservationRow (from SQLite) to a camelCase Observation.\n * Converts embedding Buffer to Float32Array for application use.\n */\nexport function rowToObservation(row: ObservationRow): Observation {\n  return {\n    rowid: row.rowid,\n    id: row.id,\n    projectHash: row.project_hash,\n    content: row.content,\n    title: row.title,\n    source: row.source,\n    sessionId: row.session_id,\n    embedding: row.embedding\n      ? new Float32Array(\n          row.embedding.buffer,\n          row.embedding.byteOffset,\n          row.embedding.byteLength / 4,\n        )\n      : null,\n    embeddingModel: row.embedding_model,\n    embeddingVersion: row.embedding_version,\n    createdAt: row.created_at,\n    updatedAt: row.updated_at,\n    deletedAt: row.deleted_at,\n  };\n}\n","import type BetterSqlite3 from 'better-sqlite3';\nimport { randomBytes } from 'node:crypto';\n\nimport { debug } from '../shared/debug.js';\nimport {\n  ObservationInsertSchema,\n  rowToObservation,\n  type Observation,\n  type ObservationInsert,\n  type ObservationRow,\n} from '../shared/types.js';\n\n/**\n * Repository for observation CRUD operations.\n *\n * Every query is scoped to the projectHash provided at construction time.\n * Callers cannot accidentally query the wrong project -- project isolation\n * is baked into every prepared statement.\n *\n * All SQL statements are prepared once in the constructor and reused for\n * every call (better-sqlite3 performance best practice).\n */\nexport class ObservationRepository {\n  private readonly db: BetterSqlite3.Database;\n  private readonly projectHash: string;\n\n  // Prepared statements (prepared once, reused for every call)\n  private readonly stmtInsert: BetterSqlite3.Statement;\n  private readonly stmtGetById: BetterSqlite3.Statement;\n  private readonly stmtGetByIdIncludingDeleted: BetterSqlite3.Statement;\n  private readonly stmtSoftDelete: BetterSqlite3.Statement;\n  private readonly stmtRestore: BetterSqlite3.Statement;\n  private readonly stmtCount: BetterSqlite3.Statement;\n\n  constructor(db: BetterSqlite3.Database, projectHash: string) {\n    this.db = db;\n    this.projectHash = projectHash;\n\n    this.stmtInsert = db.prepare(`\n      INSERT INTO observations (id, project_hash, content, title, source, session_id, embedding, embedding_model, embedding_version)\n      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n    `);\n\n    this.stmtGetById = db.prepare(`\n      SELECT * FROM observations\n      WHERE id = ? AND project_hash = ? AND deleted_at IS NULL\n    `);\n\n    this.stmtGetByIdIncludingDeleted = db.prepare(`\n      SELECT * FROM observations\n      WHERE id = ? AND project_hash = ?\n    `);\n\n    this.stmtSoftDelete = db.prepare(`\n      UPDATE observations\n      SET deleted_at = datetime('now'), updated_at = datetime('now')\n      WHERE id = ? AND project_hash = ? AND deleted_at IS NULL\n    `);\n\n    this.stmtRestore = db.prepare(`\n      UPDATE observations\n      SET deleted_at = NULL, updated_at = datetime('now')\n      WHERE id = ? AND project_hash = ?\n    `);\n\n    this.stmtCount = db.prepare(`\n      SELECT COUNT(*) AS count FROM observations\n      WHERE project_hash = ? AND deleted_at IS NULL\n    `);\n\n    debug('obs', 'ObservationRepository initialized', { projectHash });\n  }\n\n  /**\n   * Creates a new observation scoped to this repository's project.\n   * Validates input with Zod at runtime.\n   */\n  create(input: ObservationInsert): Observation {\n    const validated = ObservationInsertSchema.parse(input);\n\n    const id = randomBytes(16).toString('hex');\n    const embeddingBuffer = validated.embedding\n      ? Buffer.from(\n          validated.embedding.buffer,\n          validated.embedding.byteOffset,\n          validated.embedding.byteLength,\n        )\n      : null;\n\n    debug('obs', 'Creating observation', { source: validated.source, contentLength: validated.content.length });\n\n    this.stmtInsert.run(\n      id,\n      this.projectHash,\n      validated.content,\n      validated.title,\n      validated.source,\n      validated.sessionId,\n      embeddingBuffer,\n      validated.embeddingModel,\n      validated.embeddingVersion,\n    );\n\n    // Fetch the created row (includes generated timestamps and rowid)\n    const row = this.stmtGetById.get(id, this.projectHash) as\n      | ObservationRow\n      | undefined;\n\n    if (!row) {\n      throw new Error('Failed to retrieve newly created observation');\n    }\n\n    debug('obs', 'Observation created', { id });\n\n    return rowToObservation(row);\n  }\n\n  /**\n   * Gets an observation by ID, scoped to this project.\n   * Returns null if not found or soft-deleted.\n   */\n  getById(id: string): Observation | null {\n    const row = this.stmtGetById.get(id, this.projectHash) as\n      | ObservationRow\n      | undefined;\n    return row ? rowToObservation(row) : null;\n  }\n\n  /**\n   * Lists observations for this project, ordered by created_at DESC.\n   * Excludes soft-deleted observations.\n   */\n  list(options?: {\n    limit?: number;\n    offset?: number;\n    sessionId?: string;\n    since?: string;\n  }): Observation[] {\n    debug('obs', 'Listing observations', { ...options });\n\n    const limit = options?.limit ?? 50;\n    const offset = options?.offset ?? 0;\n\n    let sql =\n      'SELECT * FROM observations WHERE project_hash = ? AND deleted_at IS NULL';\n    const params: unknown[] = [this.projectHash];\n\n    if (options?.sessionId) {\n      sql += ' AND session_id = ?';\n      params.push(options.sessionId);\n    }\n\n    if (options?.since) {\n      sql += ' AND created_at >= ?';\n      params.push(options.since);\n    }\n\n    sql += ' ORDER BY created_at DESC, rowid DESC LIMIT ? OFFSET ?';\n    params.push(limit, offset);\n\n    const rows = this.db.prepare(sql).all(...params) as ObservationRow[];\n\n    debug('obs', 'Listed observations', { count: rows.length });\n\n    return rows.map(rowToObservation);\n  }\n\n  /**\n   * Updates an observation's content, embedding fields, or both.\n   * Always sets updated_at to current time.\n   * Scoped to this project; returns null if not found or soft-deleted.\n   */\n  update(\n    id: string,\n    updates: Partial<\n      Pick<\n        Observation,\n        'content' | 'embedding' | 'embeddingModel' | 'embeddingVersion'\n      >\n    >,\n  ): Observation | null {\n    debug('obs', 'Updating observation', { id });\n\n    const setClauses: string[] = [\"updated_at = datetime('now')\"];\n    const params: unknown[] = [];\n\n    if (updates.content !== undefined) {\n      setClauses.push('content = ?');\n      params.push(updates.content);\n    }\n\n    if (updates.embedding !== undefined) {\n      setClauses.push('embedding = ?');\n      params.push(\n        updates.embedding\n          ? Buffer.from(\n              updates.embedding.buffer,\n              updates.embedding.byteOffset,\n              updates.embedding.byteLength,\n            )\n          : null,\n      );\n    }\n\n    if (updates.embeddingModel !== undefined) {\n      setClauses.push('embedding_model = ?');\n      params.push(updates.embeddingModel);\n    }\n\n    if (updates.embeddingVersion !== undefined) {\n      setClauses.push('embedding_version = ?');\n      params.push(updates.embeddingVersion);\n    }\n\n    params.push(id, this.projectHash);\n\n    const sql = `UPDATE observations SET ${setClauses.join(', ')} WHERE id = ? AND project_hash = ? AND deleted_at IS NULL`;\n    const result = this.db.prepare(sql).run(...params);\n\n    if (result.changes === 0) {\n      debug('obs', 'Observation not found for update', { id });\n      return null;\n    }\n\n    debug('obs', 'Observation updated', { id });\n\n    return this.getById(id);\n  }\n\n  /**\n   * Soft-deletes an observation by setting deleted_at.\n   * Returns true if the observation was found and deleted.\n   */\n  softDelete(id: string): boolean {\n    debug('obs', 'Soft-deleting observation', { id });\n    const result = this.stmtSoftDelete.run(id, this.projectHash);\n    debug('obs', result.changes > 0 ? 'Observation soft-deleted' : 'Observation not found for delete', { id });\n    return result.changes > 0;\n  }\n\n  /**\n   * Restores a soft-deleted observation by clearing deleted_at.\n   * Returns true if the observation was found and restored.\n   */\n  restore(id: string): boolean {\n    const result = this.stmtRestore.run(id, this.projectHash);\n    return result.changes > 0;\n  }\n\n  /**\n   * Counts non-deleted observations for this project.\n   */\n  count(): number {\n    const row = this.stmtCount.get(this.projectHash) as { count: number };\n    return row.count;\n  }\n\n  /**\n   * Gets an observation by ID, including soft-deleted observations.\n   * Used by the recall tool for restore operations (must find purged items).\n   */\n  getByIdIncludingDeleted(id: string): Observation | null {\n    debug('obs', 'Getting observation including deleted', { id });\n    const row = this.stmtGetByIdIncludingDeleted.get(id, this.projectHash) as\n      | ObservationRow\n      | undefined;\n    return row ? rowToObservation(row) : null;\n  }\n\n  /**\n   * Lists observations for this project, including soft-deleted ones.\n   * Used by recall with include_purged: true to show all items.\n   */\n  listIncludingDeleted(options?: {\n    limit?: number;\n    offset?: number;\n  }): Observation[] {\n    const limit = options?.limit ?? 50;\n    const offset = options?.offset ?? 0;\n\n    debug('obs', 'Listing observations including deleted', { limit, offset });\n\n    const sql =\n      'SELECT * FROM observations WHERE project_hash = ? ORDER BY created_at DESC, rowid DESC LIMIT ? OFFSET ?';\n    const rows = this.db\n      .prepare(sql)\n      .all(this.projectHash, limit, offset) as ObservationRow[];\n\n    debug('obs', 'Listed observations including deleted', {\n      count: rows.length,\n    });\n\n    return rows.map(rowToObservation);\n  }\n\n  /**\n   * Searches observations by title substring (partial match via LIKE).\n   * Optionally includes soft-deleted items.\n   */\n  getByTitle(\n    title: string,\n    options?: { limit?: number; includePurged?: boolean },\n  ): Observation[] {\n    const limit = options?.limit ?? 20;\n    const includePurged = options?.includePurged ?? false;\n\n    debug('obs', 'Searching by title', { title, limit, includePurged });\n\n    let sql = 'SELECT * FROM observations WHERE project_hash = ? AND title LIKE ?';\n    if (!includePurged) {\n      sql += ' AND deleted_at IS NULL';\n    }\n    sql += ' ORDER BY created_at DESC, rowid DESC LIMIT ?';\n\n    const rows = this.db\n      .prepare(sql)\n      .all(this.projectHash, `%${title}%`, limit) as ObservationRow[];\n\n    debug('obs', 'Title search completed', { count: rows.length });\n\n    return rows.map(rowToObservation);\n  }\n}\n","import type BetterSqlite3 from 'better-sqlite3';\n\nimport { debug } from '../shared/debug.js';\nimport type { Session } from '../shared/types.js';\n\n/**\n * Raw session row from SQLite (snake_case column names).\n */\ninterface SessionRow {\n  id: string;\n  project_hash: string;\n  started_at: string;\n  ended_at: string | null;\n  summary: string | null;\n}\n\n/**\n * Maps a snake_case SessionRow to a camelCase Session interface.\n */\nfunction rowToSession(row: SessionRow): Session {\n  return {\n    id: row.id,\n    projectHash: row.project_hash,\n    startedAt: row.started_at,\n    endedAt: row.ended_at,\n    summary: row.summary,\n  };\n}\n\n/**\n * Repository for session lifecycle management.\n *\n * Every query is scoped to the projectHash provided at construction time.\n * All SQL statements are prepared once in the constructor.\n */\nexport class SessionRepository {\n  private readonly db: BetterSqlite3.Database;\n  private readonly projectHash: string;\n\n  // Prepared statements\n  private readonly stmtCreate: BetterSqlite3.Statement;\n  private readonly stmtGetById: BetterSqlite3.Statement;\n  private readonly stmtGetActive: BetterSqlite3.Statement;\n\n  constructor(db: BetterSqlite3.Database, projectHash: string) {\n    this.db = db;\n    this.projectHash = projectHash;\n\n    this.stmtCreate = db.prepare(`\n      INSERT INTO sessions (id, project_hash)\n      VALUES (?, ?)\n    `);\n\n    this.stmtGetById = db.prepare(`\n      SELECT * FROM sessions\n      WHERE id = ? AND project_hash = ?\n    `);\n\n    this.stmtGetActive = db.prepare(`\n      SELECT * FROM sessions\n      WHERE ended_at IS NULL AND project_hash = ?\n      ORDER BY started_at DESC\n      LIMIT 1\n    `);\n\n    debug('session', 'SessionRepository initialized', { projectHash });\n  }\n\n  /**\n   * Creates a new session with the given ID, scoped to this project.\n   */\n  create(id: string): Session {\n    this.stmtCreate.run(id, this.projectHash);\n\n    const row = this.stmtGetById.get(id, this.projectHash) as\n      | SessionRow\n      | undefined;\n\n    if (!row) {\n      throw new Error('Failed to retrieve newly created session');\n    }\n\n    debug('session', 'Session created', { id });\n\n    return rowToSession(row);\n  }\n\n  /**\n   * Ends a session by setting ended_at and optionally a summary.\n   * Returns the updated session or null if not found.\n   */\n  end(id: string, summary?: string): Session | null {\n    const setClauses = [\"ended_at = datetime('now')\"];\n    const params: unknown[] = [];\n\n    if (summary !== undefined) {\n      setClauses.push('summary = ?');\n      params.push(summary);\n    }\n\n    params.push(id, this.projectHash);\n\n    const sql = `UPDATE sessions SET ${setClauses.join(', ')} WHERE id = ? AND project_hash = ?`;\n    const result = this.db.prepare(sql).run(...params);\n\n    if (result.changes === 0) {\n      return null;\n    }\n\n    debug('session', 'Session ended', { id, hasSummary: !!summary });\n\n    return this.getById(id);\n  }\n\n  /**\n   * Gets a session by ID, scoped to this project.\n   */\n  getById(id: string): Session | null {\n    const row = this.stmtGetById.get(id, this.projectHash) as\n      | SessionRow\n      | undefined;\n    return row ? rowToSession(row) : null;\n  }\n\n  /**\n   * Gets the most recent sessions for this project, ordered by started_at DESC.\n   */\n  getLatest(limit?: number): Session[] {\n    const effectiveLimit = limit ?? 10;\n    const rows = this.db\n      .prepare(\n        `SELECT * FROM sessions WHERE project_hash = ? ORDER BY started_at DESC, rowid DESC LIMIT ?`,\n      )\n      .all(this.projectHash, effectiveLimit) as SessionRow[];\n    return rows.map(rowToSession);\n  }\n\n  /**\n   * Gets the currently active (not ended) session for this project.\n   * Returns the most recently started active session, or null if none.\n   */\n  getActive(): Session | null {\n    const row = this.stmtGetActive.get(this.projectHash) as\n      | SessionRow\n      | undefined;\n    return row ? rowToSession(row) : null;\n  }\n\n  /**\n   * Updates the summary column on an existing session row.\n   * Sets updated_at (via ended_at preservation) to track when the summary was written.\n   *\n   * Used by the curation module after compressing session observations.\n   */\n  updateSessionSummary(sessionId: string, summary: string): void {\n    const result = this.db\n      .prepare(\n        `UPDATE sessions SET summary = ? WHERE id = ? AND project_hash = ?`,\n      )\n      .run(summary, sessionId, this.projectHash);\n\n    if (result.changes === 0) {\n      debug('session', 'Session not found for summary update', {\n        sessionId,\n      });\n      return;\n    }\n\n    debug('session', 'Session summary updated', {\n      sessionId,\n      summaryLength: summary.length,\n    });\n  }\n}\n"],"mappings":";;;;;;;;;;;;;AAMA,IAAI,WAA2B;AAE/B,SAAS,UAAmB;AAC1B,KAAI,aAAa,KACf,YAAW,gBAAgB;AAE7B,QAAO;;;;;;;;;;;;;;AAeT,SAAgB,MACd,UACA,SACA,MACM;AACN,KAAI,CAAC,SAAS,CACZ;CAIF,IAAI,OAAO,qBADO,IAAI,MAAM,EAAC,aAAa,CACjB,cAAc,SAAS,IAAI;AACpD,KAAI,SAAS,OACX,SAAQ,IAAI,KAAK,UAAU,KAAK;AAElC,SAAQ,OAAO,MAAM,OAAO,KAAK;;;;;;;;;;;;;AAcnC,SAAgB,WACd,UACA,SACA,IACG;AACH,KAAI,CAAC,SAAS,CACZ,QAAO,IAAI;CAGb,MAAM,QAAQ,YAAY,KAAK;CAC/B,MAAM,SAAS,IAAI;AAEnB,OAAM,UAAU,GAAG,QAAQ,KADT,YAAY,KAAK,GAAG,OAAO,QAAQ,EAAE,CACf,KAAK;AAC7C,QAAO;;;;;;;;;;;;;;;;;;;;;ACxCT,MAAa,aAA0B;CACrC;EACE,SAAS;EACT,MAAM;EACN,IAAI;;;;;;;;;;;;;;;;;;;;;EAqBL;CACD;EACE,SAAS;EACT,MAAM;EACN,IAAI;;;;;;;;;;;;EAYL;CACD;EACE,SAAS;EACT,MAAM;EACN,IAAI;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA4BL;CACD;EACE,SAAS;EACT,MAAM;EACN,IAAI;;;;;;EAML;CACD;EACE,SAAS;EACT,MAAM;EACN,IAAI;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAmCL;CACD;EACE,SAAS;EACT,MAAM;EACN,IAAI;;;;;;;EAOL;CACD;EACE,SAAS;EACT,MAAM;EACN,IAAI;;;;;;;;;;;;;;;;;;;;EAoBL;CACD;EACE,SAAS;EACT,MAAM;EACN,IAAI;;;;;;;;;;;;;;EAcL;CACD;EACE,SAAS;EACT,MAAM;EACN,IAAI;;;;;;;;;;;;;;;;;;;;;;;EAuBL;CACF;;;;;;;;;;;;;;;AAgBD,SAAgB,cACd,IACA,kBACM;AAEN,IAAG,KAAK;;;;;;IAMN;CAGF,MAAM,aAAa,GAAG,QACpB,oDACD,CAAC,OAAO,CAAC,KAAK;CAGf,MAAM,kBAAkB,GAAG,QACzB,wDACD;CAGD,MAAM,iBAAiB,GAAG,aAAa,MAAiB;AACtD,KAAG,KAAK,EAAE,GAAG;AACb,kBAAgB,IAAI,EAAE,SAAS,EAAE,KAAK;GACtC;AAEF,MAAK,MAAM,aAAa,YAAY;AAClC,MAAI,UAAU,WAAW,WACvB;AAIF,OAAK,UAAU,YAAY,KAAK,UAAU,YAAY,MAAM,CAAC,iBAC3D;AAGF,iBAAe,UAAU;;;;;;;;;;;;;;;;AC/P7B,SAAgB,aAAa,QAA0C;AAErE,WAAU,QAAQ,OAAO,OAAO,EAAE,EAAE,WAAW,MAAM,CAAC;CAGtD,MAAM,KAAK,IAAI,SAAS,OAAO,OAAO;CAItC,MAAM,cAAc,GAAG,OAAO,sBAAsB,EAClD,QAAQ,MACT,CAAC;AACF,KAAI,gBAAgB,MAClB,SAAQ,KACN,sCAAsC,YAAY,wEAEnD;AAIH,IAAG,OAAO,kBAAkB,OAAO,cAAc;AAGjD,IAAG,OAAO,uBAAuB;AAGjC,IAAG,OAAO,sBAAsB;AAGhC,IAAG,OAAO,oBAAoB;AAG9B,IAAG,OAAO,sBAAsB;AAGhC,IAAG,OAAO,4BAA4B;AAEtC,OAAM,MAAM,sBAAsB;EAAE;EAAa,aAAa,OAAO;EAAa,CAAC;CAGnF,IAAI,mBAAmB;AACvB,KAAI;AACF,YAAU,KAAK,GAAG;AAClB,qBAAmB;SACb;AAIR,OAAM,MAAM,mBAAmB,sBAAsB,4CAA4C;AAGjG,eAAc,IAAI,iBAAiB;AAEnC,OAAM,MAAM,mBAAmB;EAAE,MAAM,OAAO;EAAQ;EAAkB,CAAC;AAGzE,QAAO;EACL;EACA;EAEA,QAAc;AACZ,OAAI;AAEF,OAAG,OAAO,0BAA0B;WAC9B;AAGR,SAAM,MAAM,kBAAkB;AAC9B,MAAG,OAAO;;EAGZ,aAAmB;AACjB,MAAG,OAAO,0BAA0B;;EAEvC;;;;;;;;;;AC9FH,MAAa,uBAAuB,EAAE,OAAO;CAC3C,OAAO,EAAE,QAAQ;CACjB,IAAI,EAAE,QAAQ;CACd,cAAc,EAAE,QAAQ;CACxB,SAAS,EAAE,QAAQ;CACnB,OAAO,EAAE,QAAQ,CAAC,UAAU;CAC5B,QAAQ,EAAE,QAAQ;CAClB,YAAY,EAAE,QAAQ,CAAC,UAAU;CACjC,WAAW,EAAE,WAAW,OAAO,CAAC,UAAU;CAC1C,iBAAiB,EAAE,QAAQ,CAAC,UAAU;CACtC,mBAAmB,EAAE,QAAQ,CAAC,UAAU;CACxC,YAAY,EAAE,QAAQ;CACtB,YAAY,EAAE,QAAQ;CACtB,YAAY,EAAE,QAAQ,CAAC,UAAU;CAClC,CAAC;;;;;AAqCF,MAAa,0BAA0B,EAAE,OAAO;CAC9C,SAAS,EAAE,QAAQ,CAAC,IAAI,EAAE,CAAC,IAAI,IAAQ;CACvC,OAAO,EAAE,QAAQ,CAAC,IAAI,IAAI,CAAC,UAAU,CAAC,QAAQ,KAAK;CACnD,QAAQ,EAAE,QAAQ,CAAC,QAAQ,UAAU;CACrC,WAAW,EAAE,QAAQ,CAAC,UAAU,CAAC,QAAQ,KAAK;CAC9C,WAAW,EAAE,WAAW,aAAa,CAAC,UAAU,CAAC,QAAQ,KAAK;CAC9D,gBAAgB,EAAE,QAAQ,CAAC,UAAU,CAAC,QAAQ,KAAK;CACnD,kBAAkB,EAAE,QAAQ,CAAC,UAAU,CAAC,QAAQ,KAAK;CACtD,CAAC;;;;;AA4CF,SAAgB,iBAAiB,KAAkC;AACjE,QAAO;EACL,OAAO,IAAI;EACX,IAAI,IAAI;EACR,aAAa,IAAI;EACjB,SAAS,IAAI;EACb,OAAO,IAAI;EACX,QAAQ,IAAI;EACZ,WAAW,IAAI;EACf,WAAW,IAAI,YACX,IAAI,aACF,IAAI,UAAU,QACd,IAAI,UAAU,YACd,IAAI,UAAU,aAAa,EAC5B,GACD;EACJ,gBAAgB,IAAI;EACpB,kBAAkB,IAAI;EACtB,WAAW,IAAI;EACf,WAAW,IAAI;EACf,WAAW,IAAI;EAChB;;;;;;;;;;;;;;;ACjHH,IAAa,wBAAb,MAAmC;CACjC,AAAiB;CACjB,AAAiB;CAGjB,AAAiB;CACjB,AAAiB;CACjB,AAAiB;CACjB,AAAiB;CACjB,AAAiB;CACjB,AAAiB;CAEjB,YAAY,IAA4B,aAAqB;AAC3D,OAAK,KAAK;AACV,OAAK,cAAc;AAEnB,OAAK,aAAa,GAAG,QAAQ;;;MAG3B;AAEF,OAAK,cAAc,GAAG,QAAQ;;;MAG5B;AAEF,OAAK,8BAA8B,GAAG,QAAQ;;;MAG5C;AAEF,OAAK,iBAAiB,GAAG,QAAQ;;;;MAI/B;AAEF,OAAK,cAAc,GAAG,QAAQ;;;;MAI5B;AAEF,OAAK,YAAY,GAAG,QAAQ;;;MAG1B;AAEF,QAAM,OAAO,qCAAqC,EAAE,aAAa,CAAC;;;;;;CAOpE,OAAO,OAAuC;EAC5C,MAAM,YAAY,wBAAwB,MAAM,MAAM;EAEtD,MAAM,KAAK,YAAY,GAAG,CAAC,SAAS,MAAM;EAC1C,MAAM,kBAAkB,UAAU,YAC9B,OAAO,KACL,UAAU,UAAU,QACpB,UAAU,UAAU,YACpB,UAAU,UAAU,WACrB,GACD;AAEJ,QAAM,OAAO,wBAAwB;GAAE,QAAQ,UAAU;GAAQ,eAAe,UAAU,QAAQ;GAAQ,CAAC;AAE3G,OAAK,WAAW,IACd,IACA,KAAK,aACL,UAAU,SACV,UAAU,OACV,UAAU,QACV,UAAU,WACV,iBACA,UAAU,gBACV,UAAU,iBACX;EAGD,MAAM,MAAM,KAAK,YAAY,IAAI,IAAI,KAAK,YAAY;AAItD,MAAI,CAAC,IACH,OAAM,IAAI,MAAM,+CAA+C;AAGjE,QAAM,OAAO,uBAAuB,EAAE,IAAI,CAAC;AAE3C,SAAO,iBAAiB,IAAI;;;;;;CAO9B,QAAQ,IAAgC;EACtC,MAAM,MAAM,KAAK,YAAY,IAAI,IAAI,KAAK,YAAY;AAGtD,SAAO,MAAM,iBAAiB,IAAI,GAAG;;;;;;CAOvC,KAAK,SAKa;AAChB,QAAM,OAAO,wBAAwB,EAAE,GAAG,SAAS,CAAC;EAEpD,MAAM,QAAQ,SAAS,SAAS;EAChC,MAAM,SAAS,SAAS,UAAU;EAElC,IAAI,MACF;EACF,MAAM,SAAoB,CAAC,KAAK,YAAY;AAE5C,MAAI,SAAS,WAAW;AACtB,UAAO;AACP,UAAO,KAAK,QAAQ,UAAU;;AAGhC,MAAI,SAAS,OAAO;AAClB,UAAO;AACP,UAAO,KAAK,QAAQ,MAAM;;AAG5B,SAAO;AACP,SAAO,KAAK,OAAO,OAAO;EAE1B,MAAM,OAAO,KAAK,GAAG,QAAQ,IAAI,CAAC,IAAI,GAAG,OAAO;AAEhD,QAAM,OAAO,uBAAuB,EAAE,OAAO,KAAK,QAAQ,CAAC;AAE3D,SAAO,KAAK,IAAI,iBAAiB;;;;;;;CAQnC,OACE,IACA,SAMoB;AACpB,QAAM,OAAO,wBAAwB,EAAE,IAAI,CAAC;EAE5C,MAAM,aAAuB,CAAC,+BAA+B;EAC7D,MAAM,SAAoB,EAAE;AAE5B,MAAI,QAAQ,YAAY,QAAW;AACjC,cAAW,KAAK,cAAc;AAC9B,UAAO,KAAK,QAAQ,QAAQ;;AAG9B,MAAI,QAAQ,cAAc,QAAW;AACnC,cAAW,KAAK,gBAAgB;AAChC,UAAO,KACL,QAAQ,YACJ,OAAO,KACL,QAAQ,UAAU,QAClB,QAAQ,UAAU,YAClB,QAAQ,UAAU,WACnB,GACD,KACL;;AAGH,MAAI,QAAQ,mBAAmB,QAAW;AACxC,cAAW,KAAK,sBAAsB;AACtC,UAAO,KAAK,QAAQ,eAAe;;AAGrC,MAAI,QAAQ,qBAAqB,QAAW;AAC1C,cAAW,KAAK,wBAAwB;AACxC,UAAO,KAAK,QAAQ,iBAAiB;;AAGvC,SAAO,KAAK,IAAI,KAAK,YAAY;EAEjC,MAAM,MAAM,2BAA2B,WAAW,KAAK,KAAK,CAAC;AAG7D,MAFe,KAAK,GAAG,QAAQ,IAAI,CAAC,IAAI,GAAG,OAAO,CAEvC,YAAY,GAAG;AACxB,SAAM,OAAO,oCAAoC,EAAE,IAAI,CAAC;AACxD,UAAO;;AAGT,QAAM,OAAO,uBAAuB,EAAE,IAAI,CAAC;AAE3C,SAAO,KAAK,QAAQ,GAAG;;;;;;CAOzB,WAAW,IAAqB;AAC9B,QAAM,OAAO,6BAA6B,EAAE,IAAI,CAAC;EACjD,MAAM,SAAS,KAAK,eAAe,IAAI,IAAI,KAAK,YAAY;AAC5D,QAAM,OAAO,OAAO,UAAU,IAAI,6BAA6B,oCAAoC,EAAE,IAAI,CAAC;AAC1G,SAAO,OAAO,UAAU;;;;;;CAO1B,QAAQ,IAAqB;AAE3B,SADe,KAAK,YAAY,IAAI,IAAI,KAAK,YAAY,CAC3C,UAAU;;;;;CAM1B,QAAgB;AAEd,SADY,KAAK,UAAU,IAAI,KAAK,YAAY,CACrC;;;;;;CAOb,wBAAwB,IAAgC;AACtD,QAAM,OAAO,yCAAyC,EAAE,IAAI,CAAC;EAC7D,MAAM,MAAM,KAAK,4BAA4B,IAAI,IAAI,KAAK,YAAY;AAGtE,SAAO,MAAM,iBAAiB,IAAI,GAAG;;;;;;CAOvC,qBAAqB,SAGH;EAChB,MAAM,QAAQ,SAAS,SAAS;EAChC,MAAM,SAAS,SAAS,UAAU;AAElC,QAAM,OAAO,0CAA0C;GAAE;GAAO;GAAQ,CAAC;EAIzE,MAAM,OAAO,KAAK,GACf,QAFD,0GAEa,CACZ,IAAI,KAAK,aAAa,OAAO,OAAO;AAEvC,QAAM,OAAO,yCAAyC,EACpD,OAAO,KAAK,QACb,CAAC;AAEF,SAAO,KAAK,IAAI,iBAAiB;;;;;;CAOnC,WACE,OACA,SACe;EACf,MAAM,QAAQ,SAAS,SAAS;EAChC,MAAM,gBAAgB,SAAS,iBAAiB;AAEhD,QAAM,OAAO,sBAAsB;GAAE;GAAO;GAAO;GAAe,CAAC;EAEnE,IAAI,MAAM;AACV,MAAI,CAAC,cACH,QAAO;AAET,SAAO;EAEP,MAAM,OAAO,KAAK,GACf,QAAQ,IAAI,CACZ,IAAI,KAAK,aAAa,IAAI,MAAM,IAAI,MAAM;AAE7C,QAAM,OAAO,0BAA0B,EAAE,OAAO,KAAK,QAAQ,CAAC;AAE9D,SAAO,KAAK,IAAI,iBAAiB;;;;;;;;;AC7SrC,SAAS,aAAa,KAA0B;AAC9C,QAAO;EACL,IAAI,IAAI;EACR,aAAa,IAAI;EACjB,WAAW,IAAI;EACf,SAAS,IAAI;EACb,SAAS,IAAI;EACd;;;;;;;;AASH,IAAa,oBAAb,MAA+B;CAC7B,AAAiB;CACjB,AAAiB;CAGjB,AAAiB;CACjB,AAAiB;CACjB,AAAiB;CAEjB,YAAY,IAA4B,aAAqB;AAC3D,OAAK,KAAK;AACV,OAAK,cAAc;AAEnB,OAAK,aAAa,GAAG,QAAQ;;;MAG3B;AAEF,OAAK,cAAc,GAAG,QAAQ;;;MAG5B;AAEF,OAAK,gBAAgB,GAAG,QAAQ;;;;;MAK9B;AAEF,QAAM,WAAW,iCAAiC,EAAE,aAAa,CAAC;;;;;CAMpE,OAAO,IAAqB;AAC1B,OAAK,WAAW,IAAI,IAAI,KAAK,YAAY;EAEzC,MAAM,MAAM,KAAK,YAAY,IAAI,IAAI,KAAK,YAAY;AAItD,MAAI,CAAC,IACH,OAAM,IAAI,MAAM,2CAA2C;AAG7D,QAAM,WAAW,mBAAmB,EAAE,IAAI,CAAC;AAE3C,SAAO,aAAa,IAAI;;;;;;CAO1B,IAAI,IAAY,SAAkC;EAChD,MAAM,aAAa,CAAC,6BAA6B;EACjD,MAAM,SAAoB,EAAE;AAE5B,MAAI,YAAY,QAAW;AACzB,cAAW,KAAK,cAAc;AAC9B,UAAO,KAAK,QAAQ;;AAGtB,SAAO,KAAK,IAAI,KAAK,YAAY;EAEjC,MAAM,MAAM,uBAAuB,WAAW,KAAK,KAAK,CAAC;AAGzD,MAFe,KAAK,GAAG,QAAQ,IAAI,CAAC,IAAI,GAAG,OAAO,CAEvC,YAAY,EACrB,QAAO;AAGT,QAAM,WAAW,iBAAiB;GAAE;GAAI,YAAY,CAAC,CAAC;GAAS,CAAC;AAEhE,SAAO,KAAK,QAAQ,GAAG;;;;;CAMzB,QAAQ,IAA4B;EAClC,MAAM,MAAM,KAAK,YAAY,IAAI,IAAI,KAAK,YAAY;AAGtD,SAAO,MAAM,aAAa,IAAI,GAAG;;;;;CAMnC,UAAU,OAA2B;EACnC,MAAM,iBAAiB,SAAS;AAMhC,SALa,KAAK,GACf,QACC,6FACD,CACA,IAAI,KAAK,aAAa,eAAe,CAC5B,IAAI,aAAa;;;;;;CAO/B,YAA4B;EAC1B,MAAM,MAAM,KAAK,cAAc,IAAI,KAAK,YAAY;AAGpD,SAAO,MAAM,aAAa,IAAI,GAAG;;;;;;;;CASnC,qBAAqB,WAAmB,SAAuB;AAO7D,MANe,KAAK,GACjB,QACC,oEACD,CACA,IAAI,SAAS,WAAW,KAAK,YAAY,CAEjC,YAAY,GAAG;AACxB,SAAM,WAAW,wCAAwC,EACvD,WACD,CAAC;AACF;;AAGF,QAAM,WAAW,2BAA2B;GAC1C;GACA,eAAe,QAAQ;GACxB,CAAC"}