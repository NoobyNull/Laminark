{"version":3,"file":"handler.js","names":["truncate"],"sources":["../../src/hooks/capture.ts","../../src/curation/summarizer.ts","../../src/context/injection.ts","../../src/hooks/session-lifecycle.ts","../../src/hooks/privacy-filter.ts","../../src/hooks/noise-patterns.ts","../../src/hooks/admission-filter.ts","../../src/hooks/handler.ts"],"sourcesContent":["import type { ObservationRepository } from '../storage/observations.js';\nimport { debug } from '../shared/debug.js';\n\n/**\n * Payload shape for PostToolUse / PostToolUseFailure hook events.\n * Matches the official Claude Code hook JSON format.\n */\nexport interface PostToolUsePayload {\n  session_id: string;\n  cwd: string;\n  hook_event_name: string;\n  tool_name: string;\n  tool_input: Record<string, unknown>;\n  tool_response?: Record<string, unknown>;\n  tool_use_id?: string;\n}\n\n/**\n * Truncates a string to maxLength, appending '...' if truncated.\n */\nexport function truncate(text: string, maxLength: number): string {\n  if (text.length <= maxLength) return text;\n  return text.slice(0, maxLength) + '...';\n}\n\n/**\n * Extracts a semantic observation summary from a PostToolUse payload.\n * Returns null if no meaningful observation can be derived.\n *\n * Summaries are human-readable, not raw tool output. Each tool type\n * gets a format optimized for later search and recall.\n */\nexport function extractObservation(payload: PostToolUsePayload): string | null {\n  const { tool_name, tool_input, tool_response } = payload;\n\n  switch (tool_name) {\n    case 'Write':\n      // High signal: file creation. Include path and first ~200 chars of content.\n      return `[Write] Created ${tool_input.file_path}\\n${truncate(String(tool_input.content ?? ''), 200)}`;\n\n    case 'Edit':\n      // High signal: code change. Include path, old->new summary.\n      return `[Edit] Modified ${tool_input.file_path}: replaced \"${truncate(String(tool_input.old_string ?? ''), 80)}\" with \"${truncate(String(tool_input.new_string ?? ''), 80)}\"`;\n\n    case 'Bash': {\n      // Medium signal: command execution. Include command and first ~200 chars of response.\n      const cmd = truncate(String(tool_input.command ?? ''), 100);\n      const output = truncate(JSON.stringify(tool_response ?? ''), 200);\n      return `[Bash] $ ${cmd}\\n${output}`;\n    }\n\n    case 'Read':\n      // Low signal: file reads are usually noise. Admission filter will often reject.\n      return `[Read] ${tool_input.file_path}`;\n\n    case 'Glob':\n    case 'Grep':\n      // Low signal: search operations.\n      return `[${tool_name}] pattern=${tool_input.pattern ?? ''} in ${tool_input.path ?? 'cwd'}`;\n\n    default:\n      // MCP tools and others -- capture tool name + input summary.\n      return `[${tool_name}] ${truncate(JSON.stringify(tool_input), 200)}`;\n  }\n}\n\n/**\n * Processes a PostToolUse or PostToolUseFailure event.\n *\n * Validates the input, skips self-referential mcp__laminark__ tools,\n * extracts a semantic observation summary, and persists it to the database.\n */\nexport function processPostToolUse(\n  input: Record<string, unknown>,\n  obsRepo: ObservationRepository,\n): void {\n  const toolName = input.tool_name as string | undefined;\n\n  if (!toolName) {\n    debug('hook', 'PostToolUse missing tool_name, skipping');\n    return;\n  }\n\n  // Skip self-referential capture (Laminark observing its own operations)\n  if (toolName.startsWith('mcp__laminark__')) {\n    debug('hook', 'Skipping self-referential tool', { tool: toolName });\n    return;\n  }\n\n  const payload: PostToolUsePayload = {\n    session_id: input.session_id as string,\n    cwd: input.cwd as string,\n    hook_event_name: input.hook_event_name as string,\n    tool_name: toolName,\n    tool_input: (input.tool_input as Record<string, unknown>) ?? {},\n    tool_response: input.tool_response as Record<string, unknown> | undefined,\n    tool_use_id: input.tool_use_id as string | undefined,\n  };\n\n  const summary = extractObservation(payload);\n\n  if (summary === null) {\n    debug('hook', 'No observation extracted', { tool: toolName });\n    return;\n  }\n\n  obsRepo.create({\n    content: summary,\n    source: 'hook:' + toolName,\n    sessionId: payload.session_id ?? null,\n  });\n\n  debug('hook', 'Captured observation', { tool: toolName, length: summary.length });\n}\n","import type { Observation } from '../shared/types.js';\nimport { ObservationRepository } from '../storage/observations.js';\nimport { SessionRepository } from '../storage/sessions.js';\nimport { debug } from '../shared/debug.js';\n\n/**\n * Summary result returned after generating a session summary.\n */\nexport interface SessionSummary {\n  sessionId: string;\n  summary: string;\n  observationCount: number;\n  generatedAt: string;\n}\n\n// ---------------------------------------------------------------------------\n// Heuristic patterns for extracting structured information\n// ---------------------------------------------------------------------------\n\n/** Matches file paths like src/foo/bar.ts, ./config.json, /etc/hosts */\nconst FILE_PATH_RE = /(?:^|[\\s\"'`(])([a-zA-Z0-9_./-]+\\.[a-zA-Z]{1,10})(?=[\\s\"'`),;:]|$)/g;\n\n/** Keywords indicating a decision or choice was made */\nconst DECISION_KEYWORDS = [\n  'decided',\n  'chose',\n  'will use',\n  'going with',\n  'selected',\n  'opted for',\n  'switching to',\n  'prefer',\n];\n\n/** Keywords indicating a problem was encountered */\nconst PROBLEM_KEYWORDS = [\n  'error',\n  'failed',\n  'bug',\n  'issue',\n  'fix',\n  'broken',\n  'crash',\n  'wrong',\n  'missing',\n  'undefined',\n];\n\n/** Keywords indicating a solution was applied */\nconst SOLUTION_KEYWORDS = [\n  'fixed',\n  'resolved',\n  'solved',\n  'working now',\n  'corrected',\n  'patched',\n  'addressed',\n];\n\n// ---------------------------------------------------------------------------\n// Extraction helpers\n// ---------------------------------------------------------------------------\n\n/**\n * Extracts unique file paths from observation content.\n * Filters out common false positives like version numbers (e.g., \"v1.0\").\n */\nfunction extractFilePaths(observations: Observation[]): string[] {\n  const paths = new Set<string>();\n  const falsePositiveRe = /^[vV]?\\d+\\.\\d/;\n\n  for (const obs of observations) {\n    const text = obs.content;\n    let match: RegExpExecArray | null;\n    FILE_PATH_RE.lastIndex = 0;\n    while ((match = FILE_PATH_RE.exec(text)) !== null) {\n      const path = match[1];\n      // Skip version-like patterns, single extensions, and very short matches\n      if (path.length > 3 && !falsePositiveRe.test(path)) {\n        paths.add(path);\n      }\n    }\n  }\n\n  return Array.from(paths).slice(0, 15);\n}\n\n/**\n * Extracts observations that contain decision-related keywords.\n * Returns the first sentence or first 120 characters of matching content.\n */\nfunction extractDecisions(observations: Observation[]): string[] {\n  const decisions: string[] = [];\n\n  for (const obs of observations) {\n    const lower = obs.content.toLowerCase();\n    const isDecision = DECISION_KEYWORDS.some((kw) => lower.includes(kw));\n    if (isDecision) {\n      // Take the first sentence or first 120 chars\n      const firstSentence = obs.content.split(/[.!?\\n]/)[0].trim();\n      const snippet =\n        firstSentence.length > 120\n          ? firstSentence.slice(0, 117) + '...'\n          : firstSentence;\n      if (snippet.length > 5) {\n        decisions.push(snippet);\n      }\n    }\n  }\n\n  return decisions.slice(0, 8);\n}\n\n/**\n * Extracts key activities from observations by summarizing tool usage\n * and notable actions. Prioritizes: explicit saves > problems/solutions > tool actions.\n */\nfunction extractKeyActivities(observations: Observation[]): string[] {\n  const activities: string[] = [];\n  const seen = new Set<string>();\n\n  for (const obs of observations) {\n    const lower = obs.content.toLowerCase();\n\n    // Check for problem/solution pairs\n    const isProblem = PROBLEM_KEYWORDS.some((kw) => lower.includes(kw));\n    const isSolution = SOLUTION_KEYWORDS.some((kw) => lower.includes(kw));\n\n    let label: string | null = null;\n    if (isSolution) {\n      label = 'Resolved';\n    } else if (isProblem) {\n      label = 'Issue';\n    } else if (obs.source.startsWith('mcp:')) {\n      label = 'Saved';\n    } else {\n      label = 'Action';\n    }\n\n    // Take first meaningful line as the activity summary\n    const firstLine = obs.content.split('\\n')[0].trim();\n    const snippet =\n      firstLine.length > 100\n        ? firstLine.slice(0, 97) + '...'\n        : firstLine;\n\n    if (snippet.length > 5 && !seen.has(snippet)) {\n      seen.add(snippet);\n      activities.push(`[${label}] ${snippet}`);\n    }\n  }\n\n  return activities.slice(0, 10);\n}\n\n// ---------------------------------------------------------------------------\n// Public API\n// ---------------------------------------------------------------------------\n\n/**\n * Compresses an array of session observations into a structured text summary.\n *\n * This is a deterministic heuristic summarizer -- no LLM call. It extracts:\n * - Key activities (significant actions, max 10)\n * - Decisions and insights (keyword-matched, max 8)\n * - File paths mentioned (regex-extracted, max 15)\n *\n * Target output: under 500 tokens (~2000 characters).\n * If the raw extraction exceeds this budget, sections are truncated by priority:\n * decisions > activities > files.\n */\nexport function compressObservations(observations: Observation[]): string {\n  if (observations.length === 0) {\n    return '';\n  }\n\n  const activities = extractKeyActivities(observations);\n  const decisions = extractDecisions(observations);\n  const filePaths = extractFilePaths(observations);\n\n  // Build the summary with section headers\n  const sections: string[] = [];\n\n  sections.push('## Session Summary');\n\n  // Timestamps from first and last observation\n  const sorted = [...observations].sort(\n    (a, b) => a.createdAt.localeCompare(b.createdAt),\n  );\n  const startedAt = sorted[0].createdAt;\n  const endedAt = sorted[sorted.length - 1].createdAt;\n\n  sections.push(`**Duration:** ${startedAt} to ${endedAt}`);\n  sections.push(`**Observations:** ${observations.length}`);\n\n  if (activities.length > 0) {\n    sections.push('');\n    sections.push('### Key Activities');\n    for (const activity of activities) {\n      sections.push(`- ${activity}`);\n    }\n  }\n\n  if (decisions.length > 0) {\n    sections.push('');\n    sections.push('### Decisions & Insights');\n    for (const decision of decisions) {\n      sections.push(`- ${decision}`);\n    }\n  }\n\n  if (filePaths.length > 0) {\n    sections.push('');\n    sections.push('### Files Touched');\n    for (const fp of filePaths) {\n      sections.push(`- ${fp}`);\n    }\n  }\n\n  let result = sections.join('\\n');\n\n  // Enforce ~2000 char budget (approx 500 tokens at ~4 chars/token)\n  if (result.length > 2000) {\n    // Progressively trim: files first, then activities\n    const trimmedFilePaths = filePaths.slice(0, 5);\n    const trimmedActivities = activities.slice(0, 5);\n\n    const trimSections: string[] = [];\n    trimSections.push('## Session Summary');\n    trimSections.push(`**Duration:** ${startedAt} to ${endedAt}`);\n    trimSections.push(`**Observations:** ${observations.length}`);\n\n    if (trimmedActivities.length > 0) {\n      trimSections.push('');\n      trimSections.push('### Key Activities');\n      for (const activity of trimmedActivities) {\n        trimSections.push(`- ${activity}`);\n      }\n    }\n\n    if (decisions.length > 0) {\n      trimSections.push('');\n      trimSections.push('### Decisions & Insights');\n      for (const decision of decisions.slice(0, 5)) {\n        trimSections.push(`- ${decision}`);\n      }\n    }\n\n    if (trimmedFilePaths.length > 0) {\n      trimSections.push('');\n      trimSections.push('### Files Touched');\n      for (const fp of trimmedFilePaths) {\n        trimSections.push(`- ${fp}`);\n      }\n    }\n\n    result = trimSections.join('\\n');\n  }\n\n  return result;\n}\n\n/**\n * Generates a session summary by reading all observations for the given session,\n * compressing them into a concise summary, and storing it back on the session row.\n *\n * Returns null if the session has zero observations (graceful no-op).\n *\n * @param sessionId - The session ID to summarize\n * @param obsRepo - Repository for reading observations\n * @param sessionRepo - Repository for updating the session summary\n * @returns SessionSummary or null if no observations\n */\nexport function generateSessionSummary(\n  sessionId: string,\n  obsRepo: ObservationRepository,\n  sessionRepo: SessionRepository,\n): SessionSummary | null {\n  debug('curation', 'Generating session summary', { sessionId });\n\n  // Fetch all non-deleted observations for this session, ordered by createdAt\n  const observations = obsRepo.list({\n    sessionId,\n    limit: 1000, // generous limit -- compress handles any count\n  });\n\n  if (observations.length === 0) {\n    debug('curation', 'No observations for session, skipping summary', {\n      sessionId,\n    });\n    return null;\n  }\n\n  const summary = compressObservations(observations);\n  const generatedAt = new Date().toISOString();\n\n  // Store the summary on the session row\n  sessionRepo.updateSessionSummary(sessionId, summary);\n\n  debug('curation', 'Session summary generated', {\n    sessionId,\n    observationCount: observations.length,\n    summaryLength: summary.length,\n  });\n\n  return {\n    sessionId,\n    summary,\n    observationCount: observations.length,\n    generatedAt,\n  };\n}\n","import type BetterSqlite3 from 'better-sqlite3';\n\nimport type { Observation, Session } from '../shared/types.js';\nimport type { ObservationRow } from '../shared/types.js';\nimport { rowToObservation } from '../shared/types.js';\nimport { debug } from '../shared/debug.js';\n\n/**\n * Maximum character budget for injected context (~2000 tokens at ~3 chars/token).\n * If the assembled context exceeds this, observations are truncated.\n */\nconst MAX_CONTEXT_CHARS = 6000;\n\n/**\n * Maximum number of characters to show per observation in the index.\n */\nconst OBSERVATION_CONTENT_LIMIT = 120;\n\n/**\n * Welcome message for first-ever session (no prior sessions or observations).\n */\nconst WELCOME_MESSAGE = `[Laminark] First session detected. Memory system is active and capturing observations.\nUse /laminark:remember to save important context. Use /laminark:recall to search memories.`;\n\n/**\n * Formats an ISO 8601 timestamp into a human-readable relative time string.\n *\n * @param isoDate - ISO 8601 timestamp string\n * @returns Relative time string (e.g., \"2 hours ago\", \"yesterday\", \"3 days ago\")\n */\nexport function formatRelativeTime(isoDate: string): string {\n  const now = Date.now();\n  const then = new Date(isoDate).getTime();\n  const diffMs = now - then;\n\n  if (diffMs < 0) {\n    return 'just now';\n  }\n\n  const seconds = Math.floor(diffMs / 1000);\n  const minutes = Math.floor(seconds / 60);\n  const hours = Math.floor(minutes / 60);\n  const days = Math.floor(hours / 24);\n  const weeks = Math.floor(days / 7);\n\n  if (minutes < 1) return 'just now';\n  if (minutes === 1) return '1 minute ago';\n  if (minutes < 60) return `${minutes} minutes ago`;\n  if (hours === 1) return '1 hour ago';\n  if (hours < 24) return `${hours} hours ago`;\n  if (days === 1) return 'yesterday';\n  if (days < 7) return `${days} days ago`;\n  if (weeks === 1) return '1 week ago';\n  return `${weeks} weeks ago`;\n}\n\n/**\n * Truncates a string to `maxLen` characters, appending \"...\" if truncated.\n */\nfunction truncate(text: string, maxLen: number): string {\n  // Normalize whitespace (collapse newlines/tabs to spaces)\n  const normalized = text.replace(/\\s+/g, ' ').trim();\n  if (normalized.length <= maxLen) return normalized;\n  return normalized.slice(0, maxLen) + '...';\n}\n\n/**\n * Formats the context using progressive disclosure.\n *\n * Produces a compact index suitable for Claude's context window:\n * - Last session summary (if available)\n * - Recent observation index with truncated content and IDs for drill-down\n *\n * @param lastSession - The most recent completed session (with summary), or null\n * @param recentObservations - Recent high-value observations\n * @returns Formatted context string\n */\nexport function formatContextIndex(\n  lastSession: Session | null,\n  recentObservations: Observation[],\n): string {\n  if (!lastSession && recentObservations.length === 0) {\n    return WELCOME_MESSAGE;\n  }\n\n  const lines: string[] = ['[Laminark Context - Session Recovery]', ''];\n\n  if (lastSession && lastSession.summary) {\n    const timeRange = lastSession.endedAt\n      ? `${lastSession.startedAt} to ${lastSession.endedAt}`\n      : lastSession.startedAt;\n    lines.push(`## Last Session (${timeRange})`);\n    lines.push(lastSession.summary);\n    lines.push('');\n  }\n\n  if (recentObservations.length > 0) {\n    lines.push('## Recent Memories (use search tool for full details)');\n    for (const obs of recentObservations) {\n      const shortId = obs.id.slice(0, 8);\n      const content = truncate(obs.content, OBSERVATION_CONTENT_LIMIT);\n      const relTime = formatRelativeTime(obs.createdAt);\n      lines.push(`- [${shortId}] ${content} (source: ${obs.source}, ${relTime})`);\n    }\n  }\n\n  return lines.join('\\n');\n}\n\n/**\n * Queries recent high-value observations for context injection.\n *\n * Priority ordering:\n * 1. Observations from source \"mcp:save_memory\" (user explicitly saved)\n * 2. Observations from source \"slash:remember\" (user explicitly saved via slash command)\n * 3. Most recent observations regardless of source\n *\n * Excludes deleted observations. Scoped to projectHash.\n *\n * @param db - better-sqlite3 database connection\n * @param projectHash - Project scope identifier\n * @param limit - Maximum observations to return (default 5)\n * @returns Array of high-value observations\n */\nexport function getHighValueObservations(\n  db: BetterSqlite3.Database,\n  projectHash: string,\n  limit: number = 5,\n): Observation[] {\n  debug('context', 'Querying high-value observations', { projectHash, limit });\n\n  // Query with priority: explicit saves first, then recency\n  // Uses CASE expression to sort mcp:save_memory and slash:remember sources first\n  const rows = db\n    .prepare(\n      `SELECT * FROM observations\n       WHERE project_hash = ? AND deleted_at IS NULL\n       ORDER BY\n         CASE\n           WHEN source = 'mcp:save_memory' THEN 0\n           WHEN source = 'slash:remember' THEN 0\n           ELSE 1\n         END ASC,\n         created_at DESC,\n         rowid DESC\n       LIMIT ?`,\n    )\n    .all(projectHash, limit) as ObservationRow[];\n\n  debug('context', 'High-value observations retrieved', { count: rows.length });\n\n  return rows.map(rowToObservation);\n}\n\n/**\n * Gets the most recent completed session with a non-null summary.\n *\n * @param db - better-sqlite3 database connection\n * @param projectHash - Project scope identifier\n * @returns The last session with a summary, or null\n */\nfunction getLastCompletedSession(\n  db: BetterSqlite3.Database,\n  projectHash: string,\n): Session | null {\n  const row = db\n    .prepare(\n      `SELECT * FROM sessions\n       WHERE project_hash = ? AND summary IS NOT NULL AND ended_at IS NOT NULL\n       ORDER BY ended_at DESC, rowid DESC\n       LIMIT 1`,\n    )\n    .get(projectHash) as\n    | {\n        id: string;\n        project_hash: string;\n        started_at: string;\n        ended_at: string | null;\n        summary: string | null;\n      }\n    | undefined;\n\n  if (!row) return null;\n\n  return {\n    id: row.id,\n    projectHash: row.project_hash,\n    startedAt: row.started_at,\n    endedAt: row.ended_at,\n    summary: row.summary,\n  };\n}\n\n/**\n * Assembles the complete context string for SessionStart injection.\n *\n * This is the main entry point for context injection. It queries the database\n * for the last completed session summary and recent high-value observations,\n * then formats them into a compact progressive disclosure index.\n *\n * Performance: All queries are synchronous (better-sqlite3). Expected execution\n * time is under 100ms (2-3 simple SELECT queries on indexed columns).\n *\n * Token budget: Total output stays under 2000 tokens (~6000 characters).\n * If content exceeds budget, observations are trimmed (session summary preserved).\n *\n * @param db - better-sqlite3 database connection\n * @param projectHash - Project scope identifier\n * @returns Formatted context string for injection into Claude's context window\n */\nexport function assembleSessionContext(\n  db: BetterSqlite3.Database,\n  projectHash: string,\n): string {\n  debug('context', 'Assembling session context', { projectHash });\n\n  const lastSession = getLastCompletedSession(db, projectHash);\n  const observations = getHighValueObservations(db, projectHash, 5);\n\n  let context = formatContextIndex(lastSession, observations);\n\n  // Enforce token budget: if over limit, progressively remove observations\n  if (context.length > MAX_CONTEXT_CHARS) {\n    debug('context', 'Context exceeds budget, trimming observations', {\n      length: context.length,\n      budget: MAX_CONTEXT_CHARS,\n    });\n\n    // Remove observations one by one from the end until within budget\n    let trimmedObs = observations.slice();\n    while (trimmedObs.length > 0 && context.length > MAX_CONTEXT_CHARS) {\n      trimmedObs = trimmedObs.slice(0, -1);\n      context = formatContextIndex(lastSession, trimmedObs);\n    }\n  }\n\n  debug('context', 'Session context assembled', { length: context.length });\n\n  return context;\n}\n","import type BetterSqlite3 from 'better-sqlite3';\n\nimport type { ObservationRepository } from '../storage/observations.js';\nimport type { SessionRepository } from '../storage/sessions.js';\nimport { generateSessionSummary } from '../curation/summarizer.js';\nimport { assembleSessionContext } from '../context/injection.js';\nimport { debug } from '../shared/debug.js';\n\n/**\n * Handles a SessionStart hook event.\n *\n * Creates a new session record in the database, then assembles context\n * from prior sessions and observations for injection into Claude's\n * context window.\n *\n * This hook is SYNCHRONOUS -- stdout is injected into Claude's context.\n * Must complete within 2 seconds (performance budget for sync hooks).\n * Expected execution: <100ms (session create + 2-3 SELECT queries).\n *\n * @returns Context string to write to stdout, or null if no context available\n */\nexport function handleSessionStart(\n  input: Record<string, unknown>,\n  sessionRepo: SessionRepository,\n  db: BetterSqlite3.Database,\n  projectHash: string,\n): string | null {\n  const sessionId = input.session_id as string | undefined;\n\n  if (!sessionId) {\n    debug('session', 'SessionStart missing session_id, skipping');\n    return null;\n  }\n\n  sessionRepo.create(sessionId);\n  debug('session', 'Session started', { sessionId });\n\n  // Assemble context from prior sessions and observations\n  const startTime = Date.now();\n  const context = assembleSessionContext(db, projectHash);\n  const elapsed = Date.now() - startTime;\n\n  if (elapsed > 500) {\n    debug('session', 'Context assembly slow', { elapsed, sessionId });\n  }\n\n  debug('session', 'Context assembled for injection', {\n    sessionId,\n    contextLength: context.length,\n    elapsed,\n  });\n\n  return context;\n}\n\n/**\n * Handles a SessionEnd hook event.\n *\n * Closes the session record by setting ended_at timestamp.\n */\nexport function handleSessionEnd(\n  input: Record<string, unknown>,\n  sessionRepo: SessionRepository,\n): void {\n  const sessionId = input.session_id as string | undefined;\n\n  if (!sessionId) {\n    debug('session', 'SessionEnd missing session_id, skipping');\n    return;\n  }\n\n  sessionRepo.end(sessionId);\n\n  debug('session', 'Session ended', { sessionId });\n}\n\n/**\n * Handles a Stop hook event.\n *\n * Triggers session summary generation by compressing all observations\n * from the session into a concise summary stored on the session row.\n *\n * Stop fires after SessionEnd, so the session is already closed.\n * Summary generation is heuristic (no LLM call) and typically completes\n * in under 10ms even with many observations.\n *\n * If the session has zero observations, this is a graceful no-op.\n */\nexport function handleStop(\n  input: Record<string, unknown>,\n  obsRepo: ObservationRepository,\n  sessionRepo: SessionRepository,\n): void {\n  const sessionId = input.session_id as string | undefined;\n\n  if (!sessionId) {\n    debug('session', 'Stop missing session_id, skipping');\n    return;\n  }\n\n  debug('session', 'Stop event received, generating summary', { sessionId });\n\n  const result = generateSessionSummary(sessionId, obsRepo, sessionRepo);\n\n  if (result) {\n    debug('session', 'Session summary generated', {\n      sessionId,\n      observationCount: result.observationCount,\n      summaryLength: result.summary.length,\n    });\n  } else {\n    debug('session', 'No observations to summarize', { sessionId });\n  }\n}\n","import { readFileSync } from 'node:fs';\nimport { homedir } from 'node:os';\nimport { join, basename } from 'node:path';\nimport { debug } from '../shared/debug.js';\n\n// =============================================================================\n// Types\n// =============================================================================\n\ninterface PrivacyPattern {\n  name: string;\n  regex: RegExp;\n  replacement: string;\n  category: string;\n}\n\ninterface UserPrivacyConfig {\n  additionalPatterns?: Array<{\n    regex: string;\n    replacement: string;\n  }>;\n  excludedFiles?: string[];\n}\n\n// =============================================================================\n// Default Patterns\n// =============================================================================\n\n/**\n * Built-in privacy patterns that are always active.\n *\n * Order matters: more specific patterns should come before more general ones.\n * For example, api_key patterns before env_variable to avoid double-matching.\n */\nconst DEFAULT_PRIVACY_PATTERNS: PrivacyPattern[] = [\n  {\n    name: 'private_key',\n    regex: /-----BEGIN[A-Z ]*PRIVATE KEY-----[\\s\\S]*?-----END[A-Z ]*PRIVATE KEY-----/g,\n    replacement: '[REDACTED:private_key]',\n    category: 'private_key',\n  },\n  {\n    name: 'jwt_token',\n    regex: /eyJ[A-Za-z0-9_-]+\\.eyJ[A-Za-z0-9_-]+\\.[A-Za-z0-9_-]+/g,\n    replacement: '[REDACTED:jwt]',\n    category: 'jwt',\n  },\n  {\n    name: 'connection_string',\n    regex: /(postgresql|mongodb|mysql|redis):\\/\\/[^\\s]+/g,\n    replacement: '$1://[REDACTED:connection_string]',\n    category: 'connection_string',\n  },\n  {\n    name: 'api_key_openai',\n    regex: /sk-[a-zA-Z0-9]{20,}/g,\n    replacement: '[REDACTED:api_key]',\n    category: 'api_key',\n  },\n  {\n    name: 'api_key_github',\n    regex: /ghp_[a-zA-Z0-9]{36,}/g,\n    replacement: '[REDACTED:api_key]',\n    category: 'api_key',\n  },\n  {\n    name: 'aws_access_key',\n    regex: /AKIA[A-Z0-9]{12,}/g,\n    replacement: '[REDACTED:api_key]',\n    category: 'api_key',\n  },\n  {\n    name: 'env_variable',\n    // Match KEY=value where value is 8+ chars and NOT already redacted\n    regex: /\\b([A-Z][A-Z0-9_]{2,})=([\"']?)(?!\\[REDACTED:)([^\\s\"']{8,})\\2/g,\n    replacement: '$1=[REDACTED:env]',\n    category: 'env',\n  },\n];\n\n/**\n * Default file patterns that trigger full exclusion (return null).\n */\nconst DEFAULT_EXCLUDED_FILE_PATTERNS: RegExp[] = [\n  /\\.env(\\.|$)/, // .env, .env.local, .env.production\n  /credentials/i, // credentials.json, etc.\n  /secrets/i, // secrets.yaml, etc.\n  /\\.pem$/, // SSL certificates\n  /\\.key$/, // Private keys\n  /id_rsa/, // SSH keys\n];\n\n// =============================================================================\n// Pattern Loading\n// =============================================================================\n\n/**\n * Cached patterns (loaded once per process).\n * null = not yet loaded.\n */\nlet _cachedPatterns: PrivacyPattern[] | null = null;\nlet _cachedExcludedFiles: RegExp[] | null = null;\n\n/**\n * Loads user privacy patterns from ~/.laminark/config.json.\n * Merges with defaults. Caches result.\n *\n * If the config file doesn't exist or is invalid, returns defaults only.\n */\nfunction loadPatterns(): PrivacyPattern[] {\n  if (_cachedPatterns !== null) {\n    return _cachedPatterns;\n  }\n\n  const patterns = [...DEFAULT_PRIVACY_PATTERNS];\n\n  try {\n    const configPath = join(homedir(), '.laminark', 'config.json');\n    const raw = readFileSync(configPath, 'utf-8');\n    const config = JSON.parse(raw) as Record<string, unknown>;\n    const privacy = config.privacy as UserPrivacyConfig | undefined;\n\n    if (privacy?.additionalPatterns) {\n      for (const p of privacy.additionalPatterns) {\n        patterns.push({\n          name: `user_${p.regex}`,\n          regex: new RegExp(p.regex, 'g'),\n          replacement: p.replacement,\n          category: 'user',\n        });\n      }\n      debug('privacy', 'Loaded user privacy patterns', {\n        count: privacy.additionalPatterns.length,\n      });\n    }\n  } catch {\n    // Config file doesn't exist or is invalid -- use defaults only\n  }\n\n  _cachedPatterns = patterns;\n  return patterns;\n}\n\n/**\n * Loads excluded file patterns (default + user-configured).\n */\nfunction loadExcludedFiles(): RegExp[] {\n  if (_cachedExcludedFiles !== null) {\n    return _cachedExcludedFiles;\n  }\n\n  const patterns = [...DEFAULT_EXCLUDED_FILE_PATTERNS];\n\n  try {\n    const configPath = join(homedir(), '.laminark', 'config.json');\n    const raw = readFileSync(configPath, 'utf-8');\n    const config = JSON.parse(raw) as Record<string, unknown>;\n    const privacy = config.privacy as UserPrivacyConfig | undefined;\n\n    if (privacy?.excludedFiles) {\n      for (const pattern of privacy.excludedFiles) {\n        patterns.push(new RegExp(pattern));\n      }\n    }\n  } catch {\n    // Config file doesn't exist or is invalid -- use defaults only\n  }\n\n  _cachedExcludedFiles = patterns;\n  return patterns;\n}\n\n/**\n * Reset cached patterns. Used for testing when HOME changes.\n * @internal\n */\nexport function _resetPatternCache(): void {\n  _cachedPatterns = null;\n  _cachedExcludedFiles = null;\n}\n\n// =============================================================================\n// Public API\n// =============================================================================\n\n/**\n * Checks whether a file path matches any excluded file pattern.\n *\n * Excluded files should have their observations fully dropped (return null\n * from redactSensitiveContent) rather than just redacted.\n *\n * @param filePath - The file path to check (can be absolute or relative)\n * @returns true if the file should be excluded from observation storage\n */\nexport function isExcludedFile(filePath: string): boolean {\n  const name = basename(filePath);\n  const patterns = loadExcludedFiles();\n\n  for (const pattern of patterns) {\n    if (pattern.test(name) || pattern.test(filePath)) {\n      return true;\n    }\n  }\n\n  return false;\n}\n\n/**\n * Redacts sensitive content before storage.\n *\n * - If filePath is provided and matches an excluded file pattern, returns null\n *   (the entire observation should be dropped)\n * - Otherwise, applies all privacy patterns (default + user-configured)\n *   sequentially to the text\n * - Returns the redacted text, or the original if no patterns matched\n *\n * @param text - The observation text to redact\n * @param filePath - Optional file path that triggered the observation\n * @returns Redacted text, or null if the file should be fully excluded\n */\nexport function redactSensitiveContent(\n  text: string,\n  filePath?: string,\n): string | null {\n  // Check file exclusion first\n  if (filePath && isExcludedFile(filePath)) {\n    debug('privacy', 'File excluded from observation', { filePath });\n    return null;\n  }\n\n  const patterns = loadPatterns();\n  let result = text;\n  const matchedPatterns: string[] = [];\n\n  for (const pattern of patterns) {\n    // Reset regex lastIndex (global flag means stateful)\n    pattern.regex.lastIndex = 0;\n    if (pattern.regex.test(result)) {\n      matchedPatterns.push(pattern.name);\n      // Reset lastIndex again before replace\n      pattern.regex.lastIndex = 0;\n      result = result.replace(pattern.regex, pattern.replacement);\n    }\n  }\n\n  if (matchedPatterns.length > 0) {\n    debug('privacy', 'Content redacted', { patterns: matchedPatterns });\n  }\n\n  return result;\n}\n","/**\n * Noise pattern definitions by category.\n *\n * These patterns identify low-signal content that should be rejected\n * by the admission filter before database storage.\n */\n\n/**\n * Noise pattern categories with detection regexes.\n *\n * Each category groups patterns for a specific type of noise.\n * Patterns are case-insensitive where appropriate.\n */\nexport const NOISE_PATTERNS: Record<string, RegExp[]> = {\n  BUILD_OUTPUT: [\n    /npm WARN/i,\n    /npm ERR/i,\n    /Successfully compiled/i,\n    /webpack compiled/i,\n    /error TS\\d+/i,\n    /Build completed/i,\n    /Compiling\\b/i,\n    /Module not found/i,\n  ],\n  PACKAGE_INSTALL: [\n    /added \\d+ packages?/i,\n    /npm install/i,\n    /up to date/i,\n    /removed \\d+ packages?/i,\n    /audited \\d+ packages?/i,\n  ],\n  LINTER_WARNING: [\n    /eslint/i,\n    /prettier/i,\n    /\\d+ problems?\\s*\\(/i,\n    // 3+ \"warning\" lines = noise (eslint format: \"1:1  warning  ...\")\n    /(?:.*\\bwarning\\b.*[\\n]?){3,}/i,\n  ],\n  EMPTY_OUTPUT: [\n    /^(OK|Success|Done|undefined|null)?\\s*$/is,\n  ],\n};\n\n/**\n * Checks whether the given content matches any noise pattern category.\n *\n * @param content - The text content to check\n * @returns Object with `isNoise` flag and optional `category` name\n */\nexport function isNoise(content: string): { isNoise: boolean; category?: string } {\n  // Check EMPTY_OUTPUT first -- most common rejection\n  for (const pattern of NOISE_PATTERNS.EMPTY_OUTPUT) {\n    if (pattern.test(content)) {\n      return { isNoise: true, category: 'EMPTY_OUTPUT' };\n    }\n  }\n\n  // Check other categories\n  for (const [category, patterns] of Object.entries(NOISE_PATTERNS)) {\n    if (category === 'EMPTY_OUTPUT') continue;\n    for (const pattern of patterns) {\n      if (pattern.test(content)) {\n        return { isNoise: true, category };\n      }\n    }\n  }\n\n  return { isNoise: false };\n}\n","import { isNoise } from './noise-patterns.js';\nimport { debug } from '../shared/debug.js';\n\n/**\n * Tools that are always admitted regardless of content.\n *\n * Write and Edit observations are high-signal by definition --\n * they represent intentional code changes. Content pattern matching\n * must NEVER reject these tools (see research pitfall #3).\n */\nconst HIGH_SIGNAL_TOOLS = new Set(['Write', 'Edit']);\n\n/**\n * Prefix for Laminark's own MCP tools.\n * Self-referential observations are noise -- Laminark should not\n * observe its own operations.\n */\nconst LAMINARK_MCP_PREFIX = 'mcp__laminark__';\n\n/**\n * Maximum content length before requiring decision/error indicators.\n * Content over this threshold with no meaningful indicators is likely\n * a raw file dump or verbose command output.\n */\nconst MAX_CONTENT_LENGTH = 5000;\n\n/**\n * Patterns that indicate meaningful content even in long output.\n * If content exceeds MAX_CONTENT_LENGTH, it must contain at least\n * one of these to be admitted.\n */\nconst DECISION_OR_ERROR_INDICATORS = [\n  /\\berror\\b/i,\n  /\\bfailed\\b/i,\n  /\\bexception\\b/i,\n  /\\bbug\\b/i,\n  /\\bdecided\\b/i,\n  /\\bchose\\b/i,\n  /\\bbecause\\b/i,\n  /\\binstead of\\b/i,\n];\n\n/**\n * Decides whether an observation is worth storing in the database.\n *\n * This is the primary quality gate for the observation pipeline.\n * It prevents the database from filling with noise (build output,\n * linter spam, package install logs).\n *\n * Critical rule: Write and Edit tools are NEVER rejected based on\n * content patterns alone. Tool type is the primary signal.\n *\n * @param toolName - The name of the tool that produced the observation\n * @param content - The observation content to evaluate\n * @returns true if the observation should be stored, false to reject\n */\nexport function shouldAdmit(toolName: string, content: string): boolean {\n  // Reject Laminark self-referential MCP tools\n  if (toolName.startsWith(LAMINARK_MCP_PREFIX)) {\n    debug('hook', 'Observation rejected', { tool: toolName, reason: 'self-referential' });\n    return false;\n  }\n\n  // Empty/whitespace content is always rejected, even for high-signal tools\n  if (!content || content.trim().length === 0) {\n    debug('hook', 'Observation rejected', { tool: toolName, reason: 'empty' });\n    return false;\n  }\n\n  // High-signal tools are always admitted (Write, Edit)\n  if (HIGH_SIGNAL_TOOLS.has(toolName)) {\n    return true;\n  }\n\n  // Check content against noise patterns\n  const noiseResult = isNoise(content);\n  if (noiseResult.isNoise) {\n    debug('hook', 'Observation rejected', {\n      tool: toolName,\n      reason: 'noise',\n      category: noiseResult.category,\n    });\n    return false;\n  }\n\n  // Long content without decision/error indicators is likely noise\n  if (content.length > MAX_CONTENT_LENGTH) {\n    const hasIndicator = DECISION_OR_ERROR_INDICATORS.some((pattern) =>\n      pattern.test(content),\n    );\n    if (!hasIndicator) {\n      debug('hook', 'Observation rejected', {\n        tool: toolName,\n        reason: 'long_content_no_indicators',\n        length: content.length,\n      });\n      return false;\n    }\n  }\n\n  return true;\n}\n","import { openDatabase } from '../storage/database.js';\nimport { getDatabaseConfig, getProjectHash } from '../shared/config.js';\nimport { ObservationRepository } from '../storage/observations.js';\nimport { SessionRepository } from '../storage/sessions.js';\nimport { extractObservation } from './capture.js';\nimport { handleSessionStart, handleSessionEnd, handleStop } from './session-lifecycle.js';\nimport { redactSensitiveContent, isExcludedFile } from './privacy-filter.js';\nimport { shouldAdmit } from './admission-filter.js';\nimport { debug } from '../shared/debug.js';\n\n/**\n * Hook handler entry point.\n *\n * This file is the CLI entry point for all Claude Code hook events.\n * It reads stdin JSON, opens a direct SQLite connection (no HTTP intermediary),\n * dispatches to the appropriate handler based on hook_event_name, and exits 0.\n *\n * CRITICAL CONSTRAINTS:\n * - Only SessionStart writes to stdout (synchronous hook -- stdout is injected into Claude's context window)\n * - All other hooks NEVER write to stdout (stdout output is interpreted by Claude Code)\n * - ALWAYS exits 0 (non-zero exit codes surface as errors to Claude)\n * - Opens its own database connection (WAL mode handles concurrent access with MCP server)\n * - Imports only storage modules -- NO @modelcontextprotocol/sdk (cold start overhead)\n *\n * Filter pipeline (PostToolUse/PostToolUseFailure):\n *   1. Self-referential filter (mcp__laminark__ prefix)\n *   2. Extract observation text from payload\n *   3. Privacy filter: exclude sensitive files, redact secrets\n *   4. Admission filter: reject noise content\n *   5. Store to database\n */\n\nasync function readStdin(): Promise<string> {\n  const chunks: Buffer[] = [];\n  for await (const chunk of process.stdin) {\n    chunks.push(chunk as Buffer);\n  }\n  return Buffer.concat(chunks).toString('utf-8');\n}\n\n/**\n * Processes a PostToolUse or PostToolUseFailure event through the full\n * filter pipeline: extract -> privacy -> admission -> store.\n *\n * Exported for unit testing of the pipeline logic.\n */\nexport function processPostToolUseFiltered(\n  input: Record<string, unknown>,\n  obsRepo: ObservationRepository,\n): void {\n  const toolName = input.tool_name as string | undefined;\n\n  if (!toolName) {\n    debug('hook', 'PostToolUse missing tool_name, skipping');\n    return;\n  }\n\n  // 1. Skip self-referential capture (Laminark observing its own operations)\n  if (toolName.startsWith('mcp__laminark__')) {\n    debug('hook', 'Skipping self-referential tool', { tool: toolName });\n    return;\n  }\n\n  // 2. Extract file path from tool_input (for file exclusion check)\n  const toolInput = (input.tool_input as Record<string, unknown>) ?? {};\n  const filePath = toolInput.file_path as string | undefined;\n\n  // 3. Privacy filter: check file exclusion first\n  if (filePath && isExcludedFile(filePath)) {\n    debug('hook', 'Observation excluded (sensitive file)', { tool: toolName, filePath });\n    return;\n  }\n\n  // 4. Extract observation text from payload\n  const payload = {\n    session_id: input.session_id as string,\n    cwd: input.cwd as string,\n    hook_event_name: input.hook_event_name as string,\n    tool_name: toolName,\n    tool_input: toolInput,\n    tool_response: input.tool_response as Record<string, unknown> | undefined,\n    tool_use_id: input.tool_use_id as string | undefined,\n  };\n\n  const summary = extractObservation(payload);\n\n  if (summary === null) {\n    debug('hook', 'No observation extracted', { tool: toolName });\n    return;\n  }\n\n  // 5. Privacy filter: redact sensitive content\n  const redacted = redactSensitiveContent(summary, filePath);\n\n  if (redacted === null) {\n    debug('hook', 'Observation excluded by privacy filter', { tool: toolName });\n    return;\n  }\n\n  // 6. Admission filter: reject noise\n  if (!shouldAdmit(toolName, redacted)) {\n    debug('hook', 'Observation rejected by admission filter', { tool: toolName });\n    return;\n  }\n\n  // 7. Store the filtered, redacted observation\n  obsRepo.create({\n    content: redacted,\n    source: 'hook:' + toolName,\n    sessionId: payload.session_id ?? null,\n  });\n\n  debug('hook', 'Captured observation', { tool: toolName, length: redacted.length });\n}\n\nasync function main(): Promise<void> {\n  const raw = await readStdin();\n  const input = JSON.parse(raw) as Record<string, unknown>;\n\n  const eventName = input.hook_event_name as string;\n  const cwd = input.cwd as string;\n\n  if (!eventName || !cwd) {\n    debug('hook', 'Missing hook_event_name or cwd in input');\n    return;\n  }\n\n  const projectHash = getProjectHash(cwd);\n\n  debug('hook', 'Processing hook event', { eventName, projectHash });\n\n  // Open database -- cheap with WAL mode (~2ms)\n  const laminarkDb = openDatabase(getDatabaseConfig());\n\n  try {\n    const obsRepo = new ObservationRepository(laminarkDb.db, projectHash);\n    const sessionRepo = new SessionRepository(laminarkDb.db, projectHash);\n\n    switch (eventName) {\n      case 'PostToolUse':\n      case 'PostToolUseFailure':\n        processPostToolUseFiltered(input, obsRepo);\n        break;\n      case 'SessionStart': {\n        const context = handleSessionStart(input, sessionRepo, laminarkDb.db, projectHash);\n        // SessionStart is synchronous -- stdout is injected into Claude's context window\n        if (context) {\n          process.stdout.write(context);\n        }\n        break;\n      }\n      case 'SessionEnd':\n        handleSessionEnd(input, sessionRepo);\n        break;\n      case 'Stop':\n        handleStop(input, obsRepo, sessionRepo);\n        break;\n      default:\n        debug('hook', 'Unknown hook event', { eventName });\n        break;\n    }\n  } finally {\n    laminarkDb.close();\n  }\n}\n\n// Wrap in .catch() -- hooks must NEVER fail. Always exit 0.\nmain().catch((err: Error) => {\n  debug('hook', 'Hook handler error', { error: err.message });\n});\n"],"mappings":";;;;;;;;;;AAoBA,SAAgBA,WAAS,MAAc,WAA2B;AAChE,KAAI,KAAK,UAAU,UAAW,QAAO;AACrC,QAAO,KAAK,MAAM,GAAG,UAAU,GAAG;;;;;;;;;AAUpC,SAAgB,mBAAmB,SAA4C;CAC7E,MAAM,EAAE,WAAW,YAAY,kBAAkB;AAEjD,SAAQ,WAAR;EACE,KAAK,QAEH,QAAO,mBAAmB,WAAW,UAAU,IAAIA,WAAS,OAAO,WAAW,WAAW,GAAG,EAAE,IAAI;EAEpG,KAAK,OAEH,QAAO,mBAAmB,WAAW,UAAU,cAAcA,WAAS,OAAO,WAAW,cAAc,GAAG,EAAE,GAAG,CAAC,UAAUA,WAAS,OAAO,WAAW,cAAc,GAAG,EAAE,GAAG,CAAC;EAE7K,KAAK,OAIH,QAAO,YAFKA,WAAS,OAAO,WAAW,WAAW,GAAG,EAAE,IAAI,CAEpC,IADRA,WAAS,KAAK,UAAU,iBAAiB,GAAG,EAAE,IAAI;EAInE,KAAK,OAEH,QAAO,UAAU,WAAW;EAE9B,KAAK;EACL,KAAK,OAEH,QAAO,IAAI,UAAU,YAAY,WAAW,WAAW,GAAG,MAAM,WAAW,QAAQ;EAErF,QAEE,QAAO,IAAI,UAAU,IAAIA,WAAS,KAAK,UAAU,WAAW,EAAE,IAAI;;;;;;;AC1CxE,MAAM,eAAe;;AAGrB,MAAM,oBAAoB;CACxB;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACD;;AAGD,MAAM,mBAAmB;CACvB;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACD;;AAGD,MAAM,oBAAoB;CACxB;CACA;CACA;CACA;CACA;CACA;CACA;CACD;;;;;AAUD,SAAS,iBAAiB,cAAuC;CAC/D,MAAM,wBAAQ,IAAI,KAAa;CAC/B,MAAM,kBAAkB;AAExB,MAAK,MAAM,OAAO,cAAc;EAC9B,MAAM,OAAO,IAAI;EACjB,IAAI;AACJ,eAAa,YAAY;AACzB,UAAQ,QAAQ,aAAa,KAAK,KAAK,MAAM,MAAM;GACjD,MAAM,OAAO,MAAM;AAEnB,OAAI,KAAK,SAAS,KAAK,CAAC,gBAAgB,KAAK,KAAK,CAChD,OAAM,IAAI,KAAK;;;AAKrB,QAAO,MAAM,KAAK,MAAM,CAAC,MAAM,GAAG,GAAG;;;;;;AAOvC,SAAS,iBAAiB,cAAuC;CAC/D,MAAM,YAAsB,EAAE;AAE9B,MAAK,MAAM,OAAO,cAAc;EAC9B,MAAM,QAAQ,IAAI,QAAQ,aAAa;AAEvC,MADmB,kBAAkB,MAAM,OAAO,MAAM,SAAS,GAAG,CAAC,EACrD;GAEd,MAAM,gBAAgB,IAAI,QAAQ,MAAM,UAAU,CAAC,GAAG,MAAM;GAC5D,MAAM,UACJ,cAAc,SAAS,MACnB,cAAc,MAAM,GAAG,IAAI,GAAG,QAC9B;AACN,OAAI,QAAQ,SAAS,EACnB,WAAU,KAAK,QAAQ;;;AAK7B,QAAO,UAAU,MAAM,GAAG,EAAE;;;;;;AAO9B,SAAS,qBAAqB,cAAuC;CACnE,MAAM,aAAuB,EAAE;CAC/B,MAAM,uBAAO,IAAI,KAAa;AAE9B,MAAK,MAAM,OAAO,cAAc;EAC9B,MAAM,QAAQ,IAAI,QAAQ,aAAa;EAGvC,MAAM,YAAY,iBAAiB,MAAM,OAAO,MAAM,SAAS,GAAG,CAAC;EACnE,MAAM,aAAa,kBAAkB,MAAM,OAAO,MAAM,SAAS,GAAG,CAAC;EAErE,IAAI,QAAuB;AAC3B,MAAI,WACF,SAAQ;WACC,UACT,SAAQ;WACC,IAAI,OAAO,WAAW,OAAO,CACtC,SAAQ;MAER,SAAQ;EAIV,MAAM,YAAY,IAAI,QAAQ,MAAM,KAAK,CAAC,GAAG,MAAM;EACnD,MAAM,UACJ,UAAU,SAAS,MACf,UAAU,MAAM,GAAG,GAAG,GAAG,QACzB;AAEN,MAAI,QAAQ,SAAS,KAAK,CAAC,KAAK,IAAI,QAAQ,EAAE;AAC5C,QAAK,IAAI,QAAQ;AACjB,cAAW,KAAK,IAAI,MAAM,IAAI,UAAU;;;AAI5C,QAAO,WAAW,MAAM,GAAG,GAAG;;;;;;;;;;;;;;AAmBhC,SAAgB,qBAAqB,cAAqC;AACxE,KAAI,aAAa,WAAW,EAC1B,QAAO;CAGT,MAAM,aAAa,qBAAqB,aAAa;CACrD,MAAM,YAAY,iBAAiB,aAAa;CAChD,MAAM,YAAY,iBAAiB,aAAa;CAGhD,MAAM,WAAqB,EAAE;AAE7B,UAAS,KAAK,qBAAqB;CAGnC,MAAM,SAAS,CAAC,GAAG,aAAa,CAAC,MAC9B,GAAG,MAAM,EAAE,UAAU,cAAc,EAAE,UAAU,CACjD;CACD,MAAM,YAAY,OAAO,GAAG;CAC5B,MAAM,UAAU,OAAO,OAAO,SAAS,GAAG;AAE1C,UAAS,KAAK,iBAAiB,UAAU,MAAM,UAAU;AACzD,UAAS,KAAK,qBAAqB,aAAa,SAAS;AAEzD,KAAI,WAAW,SAAS,GAAG;AACzB,WAAS,KAAK,GAAG;AACjB,WAAS,KAAK,qBAAqB;AACnC,OAAK,MAAM,YAAY,WACrB,UAAS,KAAK,KAAK,WAAW;;AAIlC,KAAI,UAAU,SAAS,GAAG;AACxB,WAAS,KAAK,GAAG;AACjB,WAAS,KAAK,2BAA2B;AACzC,OAAK,MAAM,YAAY,UACrB,UAAS,KAAK,KAAK,WAAW;;AAIlC,KAAI,UAAU,SAAS,GAAG;AACxB,WAAS,KAAK,GAAG;AACjB,WAAS,KAAK,oBAAoB;AAClC,OAAK,MAAM,MAAM,UACf,UAAS,KAAK,KAAK,KAAK;;CAI5B,IAAI,SAAS,SAAS,KAAK,KAAK;AAGhC,KAAI,OAAO,SAAS,KAAM;EAExB,MAAM,mBAAmB,UAAU,MAAM,GAAG,EAAE;EAC9C,MAAM,oBAAoB,WAAW,MAAM,GAAG,EAAE;EAEhD,MAAM,eAAyB,EAAE;AACjC,eAAa,KAAK,qBAAqB;AACvC,eAAa,KAAK,iBAAiB,UAAU,MAAM,UAAU;AAC7D,eAAa,KAAK,qBAAqB,aAAa,SAAS;AAE7D,MAAI,kBAAkB,SAAS,GAAG;AAChC,gBAAa,KAAK,GAAG;AACrB,gBAAa,KAAK,qBAAqB;AACvC,QAAK,MAAM,YAAY,kBACrB,cAAa,KAAK,KAAK,WAAW;;AAItC,MAAI,UAAU,SAAS,GAAG;AACxB,gBAAa,KAAK,GAAG;AACrB,gBAAa,KAAK,2BAA2B;AAC7C,QAAK,MAAM,YAAY,UAAU,MAAM,GAAG,EAAE,CAC1C,cAAa,KAAK,KAAK,WAAW;;AAItC,MAAI,iBAAiB,SAAS,GAAG;AAC/B,gBAAa,KAAK,GAAG;AACrB,gBAAa,KAAK,oBAAoB;AACtC,QAAK,MAAM,MAAM,iBACf,cAAa,KAAK,KAAK,KAAK;;AAIhC,WAAS,aAAa,KAAK,KAAK;;AAGlC,QAAO;;;;;;;;;;;;;AAcT,SAAgB,uBACd,WACA,SACA,aACuB;AACvB,OAAM,YAAY,8BAA8B,EAAE,WAAW,CAAC;CAG9D,MAAM,eAAe,QAAQ,KAAK;EAChC;EACA,OAAO;EACR,CAAC;AAEF,KAAI,aAAa,WAAW,GAAG;AAC7B,QAAM,YAAY,iDAAiD,EACjE,WACD,CAAC;AACF,SAAO;;CAGT,MAAM,UAAU,qBAAqB,aAAa;CAClD,MAAM,+BAAc,IAAI,MAAM,EAAC,aAAa;AAG5C,aAAY,qBAAqB,WAAW,QAAQ;AAEpD,OAAM,YAAY,6BAA6B;EAC7C;EACA,kBAAkB,aAAa;EAC/B,eAAe,QAAQ;EACxB,CAAC;AAEF,QAAO;EACL;EACA;EACA,kBAAkB,aAAa;EAC/B;EACD;;;;;;;;;AC3SH,MAAM,oBAAoB;;;;AAK1B,MAAM,4BAA4B;;;;AAKlC,MAAM,kBAAkB;;;;;;;;AASxB,SAAgB,mBAAmB,SAAyB;CAG1D,MAAM,SAFM,KAAK,KAAK,GACT,IAAI,KAAK,QAAQ,CAAC,SAAS;AAGxC,KAAI,SAAS,EACX,QAAO;CAGT,MAAM,UAAU,KAAK,MAAM,SAAS,IAAK;CACzC,MAAM,UAAU,KAAK,MAAM,UAAU,GAAG;CACxC,MAAM,QAAQ,KAAK,MAAM,UAAU,GAAG;CACtC,MAAM,OAAO,KAAK,MAAM,QAAQ,GAAG;CACnC,MAAM,QAAQ,KAAK,MAAM,OAAO,EAAE;AAElC,KAAI,UAAU,EAAG,QAAO;AACxB,KAAI,YAAY,EAAG,QAAO;AAC1B,KAAI,UAAU,GAAI,QAAO,GAAG,QAAQ;AACpC,KAAI,UAAU,EAAG,QAAO;AACxB,KAAI,QAAQ,GAAI,QAAO,GAAG,MAAM;AAChC,KAAI,SAAS,EAAG,QAAO;AACvB,KAAI,OAAO,EAAG,QAAO,GAAG,KAAK;AAC7B,KAAI,UAAU,EAAG,QAAO;AACxB,QAAO,GAAG,MAAM;;;;;AAMlB,SAAS,SAAS,MAAc,QAAwB;CAEtD,MAAM,aAAa,KAAK,QAAQ,QAAQ,IAAI,CAAC,MAAM;AACnD,KAAI,WAAW,UAAU,OAAQ,QAAO;AACxC,QAAO,WAAW,MAAM,GAAG,OAAO,GAAG;;;;;;;;;;;;;AAcvC,SAAgB,mBACd,aACA,oBACQ;AACR,KAAI,CAAC,eAAe,mBAAmB,WAAW,EAChD,QAAO;CAGT,MAAM,QAAkB,CAAC,yCAAyC,GAAG;AAErE,KAAI,eAAe,YAAY,SAAS;EACtC,MAAM,YAAY,YAAY,UAC1B,GAAG,YAAY,UAAU,MAAM,YAAY,YAC3C,YAAY;AAChB,QAAM,KAAK,oBAAoB,UAAU,GAAG;AAC5C,QAAM,KAAK,YAAY,QAAQ;AAC/B,QAAM,KAAK,GAAG;;AAGhB,KAAI,mBAAmB,SAAS,GAAG;AACjC,QAAM,KAAK,wDAAwD;AACnE,OAAK,MAAM,OAAO,oBAAoB;GACpC,MAAM,UAAU,IAAI,GAAG,MAAM,GAAG,EAAE;GAClC,MAAM,UAAU,SAAS,IAAI,SAAS,0BAA0B;GAChE,MAAM,UAAU,mBAAmB,IAAI,UAAU;AACjD,SAAM,KAAK,MAAM,QAAQ,IAAI,QAAQ,YAAY,IAAI,OAAO,IAAI,QAAQ,GAAG;;;AAI/E,QAAO,MAAM,KAAK,KAAK;;;;;;;;;;;;;;;;;AAkBzB,SAAgB,yBACd,IACA,aACA,QAAgB,GACD;AACf,OAAM,WAAW,oCAAoC;EAAE;EAAa;EAAO,CAAC;CAI5E,MAAM,OAAO,GACV,QACC;;;;;;;;;;gBAWD,CACA,IAAI,aAAa,MAAM;AAE1B,OAAM,WAAW,qCAAqC,EAAE,OAAO,KAAK,QAAQ,CAAC;AAE7E,QAAO,KAAK,IAAI,iBAAiB;;;;;;;;;AAUnC,SAAS,wBACP,IACA,aACgB;CAChB,MAAM,MAAM,GACT,QACC;;;gBAID,CACA,IAAI,YAAY;AAUnB,KAAI,CAAC,IAAK,QAAO;AAEjB,QAAO;EACL,IAAI,IAAI;EACR,aAAa,IAAI;EACjB,WAAW,IAAI;EACf,SAAS,IAAI;EACb,SAAS,IAAI;EACd;;;;;;;;;;;;;;;;;;;AAoBH,SAAgB,uBACd,IACA,aACQ;AACR,OAAM,WAAW,8BAA8B,EAAE,aAAa,CAAC;CAE/D,MAAM,cAAc,wBAAwB,IAAI,YAAY;CAC5D,MAAM,eAAe,yBAAyB,IAAI,aAAa,EAAE;CAEjE,IAAI,UAAU,mBAAmB,aAAa,aAAa;AAG3D,KAAI,QAAQ,SAAS,mBAAmB;AACtC,QAAM,WAAW,iDAAiD;GAChE,QAAQ,QAAQ;GAChB,QAAQ;GACT,CAAC;EAGF,IAAI,aAAa,aAAa,OAAO;AACrC,SAAO,WAAW,SAAS,KAAK,QAAQ,SAAS,mBAAmB;AAClE,gBAAa,WAAW,MAAM,GAAG,GAAG;AACpC,aAAU,mBAAmB,aAAa,WAAW;;;AAIzD,OAAM,WAAW,6BAA6B,EAAE,QAAQ,QAAQ,QAAQ,CAAC;AAEzE,QAAO;;;;;;;;;;;;;;;;;;ACzNT,SAAgB,mBACd,OACA,aACA,IACA,aACe;CACf,MAAM,YAAY,MAAM;AAExB,KAAI,CAAC,WAAW;AACd,QAAM,WAAW,4CAA4C;AAC7D,SAAO;;AAGT,aAAY,OAAO,UAAU;AAC7B,OAAM,WAAW,mBAAmB,EAAE,WAAW,CAAC;CAGlD,MAAM,YAAY,KAAK,KAAK;CAC5B,MAAM,UAAU,uBAAuB,IAAI,YAAY;CACvD,MAAM,UAAU,KAAK,KAAK,GAAG;AAE7B,KAAI,UAAU,IACZ,OAAM,WAAW,yBAAyB;EAAE;EAAS;EAAW,CAAC;AAGnE,OAAM,WAAW,mCAAmC;EAClD;EACA,eAAe,QAAQ;EACvB;EACD,CAAC;AAEF,QAAO;;;;;;;AAQT,SAAgB,iBACd,OACA,aACM;CACN,MAAM,YAAY,MAAM;AAExB,KAAI,CAAC,WAAW;AACd,QAAM,WAAW,0CAA0C;AAC3D;;AAGF,aAAY,IAAI,UAAU;AAE1B,OAAM,WAAW,iBAAiB,EAAE,WAAW,CAAC;;;;;;;;;;;;;;AAelD,SAAgB,WACd,OACA,SACA,aACM;CACN,MAAM,YAAY,MAAM;AAExB,KAAI,CAAC,WAAW;AACd,QAAM,WAAW,oCAAoC;AACrD;;AAGF,OAAM,WAAW,2CAA2C,EAAE,WAAW,CAAC;CAE1E,MAAM,SAAS,uBAAuB,WAAW,SAAS,YAAY;AAEtE,KAAI,OACF,OAAM,WAAW,6BAA6B;EAC5C;EACA,kBAAkB,OAAO;EACzB,eAAe,OAAO,QAAQ;EAC/B,CAAC;KAEF,OAAM,WAAW,gCAAgC,EAAE,WAAW,CAAC;;;;;;;;;;;AC7EnE,MAAM,2BAA6C;CACjD;EACE,MAAM;EACN,OAAO;EACP,aAAa;EACb,UAAU;EACX;CACD;EACE,MAAM;EACN,OAAO;EACP,aAAa;EACb,UAAU;EACX;CACD;EACE,MAAM;EACN,OAAO;EACP,aAAa;EACb,UAAU;EACX;CACD;EACE,MAAM;EACN,OAAO;EACP,aAAa;EACb,UAAU;EACX;CACD;EACE,MAAM;EACN,OAAO;EACP,aAAa;EACb,UAAU;EACX;CACD;EACE,MAAM;EACN,OAAO;EACP,aAAa;EACb,UAAU;EACX;CACD;EACE,MAAM;EAEN,OAAO;EACP,aAAa;EACb,UAAU;EACX;CACF;;;;AAKD,MAAM,iCAA2C;CAC/C;CACA;CACA;CACA;CACA;CACA;CACD;;;;;AAUD,IAAI,kBAA2C;AAC/C,IAAI,uBAAwC;;;;;;;AAQ5C,SAAS,eAAiC;AACxC,KAAI,oBAAoB,KACtB,QAAO;CAGT,MAAM,WAAW,CAAC,GAAG,yBAAyB;AAE9C,KAAI;EAEF,MAAM,MAAM,aADO,KAAK,SAAS,EAAE,aAAa,cAAc,EACzB,QAAQ;EAE7C,MAAM,UADS,KAAK,MAAM,IAAI,CACP;AAEvB,MAAI,SAAS,oBAAoB;AAC/B,QAAK,MAAM,KAAK,QAAQ,mBACtB,UAAS,KAAK;IACZ,MAAM,QAAQ,EAAE;IAChB,OAAO,IAAI,OAAO,EAAE,OAAO,IAAI;IAC/B,aAAa,EAAE;IACf,UAAU;IACX,CAAC;AAEJ,SAAM,WAAW,gCAAgC,EAC/C,OAAO,QAAQ,mBAAmB,QACnC,CAAC;;SAEE;AAIR,mBAAkB;AAClB,QAAO;;;;;AAMT,SAAS,oBAA8B;AACrC,KAAI,yBAAyB,KAC3B,QAAO;CAGT,MAAM,WAAW,CAAC,GAAG,+BAA+B;AAEpD,KAAI;EAEF,MAAM,MAAM,aADO,KAAK,SAAS,EAAE,aAAa,cAAc,EACzB,QAAQ;EAE7C,MAAM,UADS,KAAK,MAAM,IAAI,CACP;AAEvB,MAAI,SAAS,cACX,MAAK,MAAM,WAAW,QAAQ,cAC5B,UAAS,KAAK,IAAI,OAAO,QAAQ,CAAC;SAGhC;AAIR,wBAAuB;AACvB,QAAO;;;;;;;;;;;AAyBT,SAAgB,eAAe,UAA2B;CACxD,MAAM,OAAO,SAAS,SAAS;CAC/B,MAAM,WAAW,mBAAmB;AAEpC,MAAK,MAAM,WAAW,SACpB,KAAI,QAAQ,KAAK,KAAK,IAAI,QAAQ,KAAK,SAAS,CAC9C,QAAO;AAIX,QAAO;;;;;;;;;;;;;;;AAgBT,SAAgB,uBACd,MACA,UACe;AAEf,KAAI,YAAY,eAAe,SAAS,EAAE;AACxC,QAAM,WAAW,kCAAkC,EAAE,UAAU,CAAC;AAChE,SAAO;;CAGT,MAAM,WAAW,cAAc;CAC/B,IAAI,SAAS;CACb,MAAM,kBAA4B,EAAE;AAEpC,MAAK,MAAM,WAAW,UAAU;AAE9B,UAAQ,MAAM,YAAY;AAC1B,MAAI,QAAQ,MAAM,KAAK,OAAO,EAAE;AAC9B,mBAAgB,KAAK,QAAQ,KAAK;AAElC,WAAQ,MAAM,YAAY;AAC1B,YAAS,OAAO,QAAQ,QAAQ,OAAO,QAAQ,YAAY;;;AAI/D,KAAI,gBAAgB,SAAS,EAC3B,OAAM,WAAW,oBAAoB,EAAE,UAAU,iBAAiB,CAAC;AAGrE,QAAO;;;;;;;;;;;;;;;;;AC5OT,MAAa,iBAA2C;CACtD,cAAc;EACZ;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACD;CACD,iBAAiB;EACf;EACA;EACA;EACA;EACA;EACD;CACD,gBAAgB;EACd;EACA;EACA;EAEA;EACD;CACD,cAAc,CACZ,2CACD;CACF;;;;;;;AAQD,SAAgB,QAAQ,SAA0D;AAEhF,MAAK,MAAM,WAAW,eAAe,aACnC,KAAI,QAAQ,KAAK,QAAQ,CACvB,QAAO;EAAE,SAAS;EAAM,UAAU;EAAgB;AAKtD,MAAK,MAAM,CAAC,UAAU,aAAa,OAAO,QAAQ,eAAe,EAAE;AACjE,MAAI,aAAa,eAAgB;AACjC,OAAK,MAAM,WAAW,SACpB,KAAI,QAAQ,KAAK,QAAQ,CACvB,QAAO;GAAE,SAAS;GAAM;GAAU;;AAKxC,QAAO,EAAE,SAAS,OAAO;;;;;;;;;;;;ACzD3B,MAAM,oBAAoB,IAAI,IAAI,CAAC,SAAS,OAAO,CAAC;;;;;;AAOpD,MAAM,sBAAsB;;;;;;AAO5B,MAAM,qBAAqB;;;;;;AAO3B,MAAM,+BAA+B;CACnC;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACD;;;;;;;;;;;;;;;AAgBD,SAAgB,YAAY,UAAkB,SAA0B;AAEtE,KAAI,SAAS,WAAW,oBAAoB,EAAE;AAC5C,QAAM,QAAQ,wBAAwB;GAAE,MAAM;GAAU,QAAQ;GAAoB,CAAC;AACrF,SAAO;;AAIT,KAAI,CAAC,WAAW,QAAQ,MAAM,CAAC,WAAW,GAAG;AAC3C,QAAM,QAAQ,wBAAwB;GAAE,MAAM;GAAU,QAAQ;GAAS,CAAC;AAC1E,SAAO;;AAIT,KAAI,kBAAkB,IAAI,SAAS,CACjC,QAAO;CAIT,MAAM,cAAc,QAAQ,QAAQ;AACpC,KAAI,YAAY,SAAS;AACvB,QAAM,QAAQ,wBAAwB;GACpC,MAAM;GACN,QAAQ;GACR,UAAU,YAAY;GACvB,CAAC;AACF,SAAO;;AAIT,KAAI,QAAQ,SAAS,oBAInB;MAAI,CAHiB,6BAA6B,MAAM,YACtD,QAAQ,KAAK,QAAQ,CACtB,EACkB;AACjB,SAAM,QAAQ,wBAAwB;IACpC,MAAM;IACN,QAAQ;IACR,QAAQ,QAAQ;IACjB,CAAC;AACF,UAAO;;;AAIX,QAAO;;;;;;;;;;;;;;;;;;;;;;;;;;ACpET,eAAe,YAA6B;CAC1C,MAAM,SAAmB,EAAE;AAC3B,YAAW,MAAM,SAAS,QAAQ,MAChC,QAAO,KAAK,MAAgB;AAE9B,QAAO,OAAO,OAAO,OAAO,CAAC,SAAS,QAAQ;;;;;;;;AAShD,SAAgB,2BACd,OACA,SACM;CACN,MAAM,WAAW,MAAM;AAEvB,KAAI,CAAC,UAAU;AACb,QAAM,QAAQ,0CAA0C;AACxD;;AAIF,KAAI,SAAS,WAAW,kBAAkB,EAAE;AAC1C,QAAM,QAAQ,kCAAkC,EAAE,MAAM,UAAU,CAAC;AACnE;;CAIF,MAAM,YAAa,MAAM,cAA0C,EAAE;CACrE,MAAM,WAAW,UAAU;AAG3B,KAAI,YAAY,eAAe,SAAS,EAAE;AACxC,QAAM,QAAQ,yCAAyC;GAAE,MAAM;GAAU;GAAU,CAAC;AACpF;;CAIF,MAAM,UAAU;EACd,YAAY,MAAM;EAClB,KAAK,MAAM;EACX,iBAAiB,MAAM;EACvB,WAAW;EACX,YAAY;EACZ,eAAe,MAAM;EACrB,aAAa,MAAM;EACpB;CAED,MAAM,UAAU,mBAAmB,QAAQ;AAE3C,KAAI,YAAY,MAAM;AACpB,QAAM,QAAQ,4BAA4B,EAAE,MAAM,UAAU,CAAC;AAC7D;;CAIF,MAAM,WAAW,uBAAuB,SAAS,SAAS;AAE1D,KAAI,aAAa,MAAM;AACrB,QAAM,QAAQ,0CAA0C,EAAE,MAAM,UAAU,CAAC;AAC3E;;AAIF,KAAI,CAAC,YAAY,UAAU,SAAS,EAAE;AACpC,QAAM,QAAQ,4CAA4C,EAAE,MAAM,UAAU,CAAC;AAC7E;;AAIF,SAAQ,OAAO;EACb,SAAS;EACT,QAAQ,UAAU;EAClB,WAAW,QAAQ,cAAc;EAClC,CAAC;AAEF,OAAM,QAAQ,wBAAwB;EAAE,MAAM;EAAU,QAAQ,SAAS;EAAQ,CAAC;;AAGpF,eAAe,OAAsB;CACnC,MAAM,MAAM,MAAM,WAAW;CAC7B,MAAM,QAAQ,KAAK,MAAM,IAAI;CAE7B,MAAM,YAAY,MAAM;CACxB,MAAM,MAAM,MAAM;AAElB,KAAI,CAAC,aAAa,CAAC,KAAK;AACtB,QAAM,QAAQ,0CAA0C;AACxD;;CAGF,MAAM,cAAc,eAAe,IAAI;AAEvC,OAAM,QAAQ,yBAAyB;EAAE;EAAW;EAAa,CAAC;CAGlE,MAAM,aAAa,aAAa,mBAAmB,CAAC;AAEpD,KAAI;EACF,MAAM,UAAU,IAAI,sBAAsB,WAAW,IAAI,YAAY;EACrE,MAAM,cAAc,IAAI,kBAAkB,WAAW,IAAI,YAAY;AAErE,UAAQ,WAAR;GACE,KAAK;GACL,KAAK;AACH,+BAA2B,OAAO,QAAQ;AAC1C;GACF,KAAK,gBAAgB;IACnB,MAAM,UAAU,mBAAmB,OAAO,aAAa,WAAW,IAAI,YAAY;AAElF,QAAI,QACF,SAAQ,OAAO,MAAM,QAAQ;AAE/B;;GAEF,KAAK;AACH,qBAAiB,OAAO,YAAY;AACpC;GACF,KAAK;AACH,eAAW,OAAO,SAAS,YAAY;AACvC;GACF;AACE,UAAM,QAAQ,sBAAsB,EAAE,WAAW,CAAC;AAClD;;WAEI;AACR,aAAW,OAAO;;;AAKtB,MAAM,CAAC,OAAO,QAAe;AAC3B,OAAM,QAAQ,sBAAsB,EAAE,OAAO,IAAI,SAAS,CAAC;EAC3D"}